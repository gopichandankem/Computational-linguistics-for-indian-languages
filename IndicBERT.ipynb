{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3lByD4-5PdZ"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uCOLc2AmjqRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f427080f-ce61-4bc0-f3c2-fd53bb6d3096"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip3 install sentencepiece\n",
        "!pip3 install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o-NigbFv72g"
      },
      "source": [
        "# Running the IndicNER Model\n",
        "\n",
        "Let's try annotating some Indian language sentences and get the named entities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5TuaafFkGF8"
      },
      "outputs": [],
      "source": [
        "# Import all the necessary classes and initialize the tokenizer and model.\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQCqprq_kkjT"
      },
      "outputs": [],
      "source": [
        "def get_predictions( sentence, tokenizer, model ):\n",
        "  # Let us first tokenize the sentence - split words into subwords\n",
        "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # we will send the tokenized sentence to the model to get predictions\n",
        "    logits = model(**tok_sentence).logits.argmax(-1)\n",
        "\n",
        "    # We will map the maximum predicted class id with the class label\n",
        "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
        "\n",
        "    predicted_labels = []\n",
        "\n",
        "    previous_token_id = 0\n",
        "    # we need to assign the named entity label to the head word and not the following sub-words\n",
        "    word_ids = tok_sentence.word_ids()\n",
        "    for word_index in range(len(word_ids)):\n",
        "        if word_ids[word_index] == None:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        elif word_ids[word_index] == previous_token_id:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        else:\n",
        "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
        "            previous_token_id = word_ids[word_index]\n",
        "\n",
        "    return predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_A4NrfEdxG9q",
        "outputId": "5f759d47-47ce-49fb-ecde-737295b69bca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ఎన్నికల\tO\n",
            "ప్రకటన\tO\n",
            "వెలువడినది\tO\n",
            "లగాయతు..\tO\n",
            "సీట్ల\tO\n",
            "పంపకం\tO\n",
            "కోసం\tO\n",
            "కొట్టుకోవడమే\tO\n",
            "మహాకూటమికి\tO\n",
            "సరిపోతున్నది.\tO\n",
            "ప్రతిరోజూ\tO\n",
            "ఉదయం\tO\n",
            "ఇంట్లో\tO\n",
            "టిఫిన్\tO\n",
            "చెయ్యడం,\tO\n",
            "గోల్కొండ\tO\n",
            "రిసారట్స్‌కు\tO\n",
            "వెళ్లి\tO\n",
            "పిచ్చాపాటీ\tO\n",
            "మాట్లాడుకుని\tO\n",
            "భోజనం\tO\n",
            "చెయ్యడం,\tO\n",
            "ఇంటికి\tO\n",
            "వెళ్లడం,\tO\n",
            "మరునాడు\tO\n",
            "మళ్ళీ\tO\n",
            "అదే\tO\n",
            "తంతు…కాంగ్రెస్\tO\n",
            "పార్టీకి\tO\n",
            "కార్యకర్తలు\tO\n",
            "తక్కువ,\tO\n",
            "నాయకులు\tO\n",
            "ఎక్కువ.\tO\n",
            "సర్పంచ్\tO\n",
            "గా\tO\n",
            "కూడా\tB-ORG\n",
            "చేయనివాడు\tO\n",
            "ముఖ్యమంత్రి\tO\n",
            "కావాలనుకుంటారు\tO\n",
            "ఆ\tO\n",
            "పార్టీలో.\tO\n",
            "అందుకే\tO\n",
            "ఎప్పుడు\tO\n",
            "ఎన్నికలు\tO\n",
            "వచ్చినా,\tO\n",
            "కాంగ్రెస్\tO\n",
            "పార్టీలో\tO\n",
            "అంతర్గత\tO\n",
            "యుద్ధం\tO\n",
            "మొదలవుతుంది.\tO\n",
            "వారికి\tO\n",
            "వారే\tO\n",
            "వెన్నుపోట్లు\tO\n",
            "పొడుచుకుంటారు.\tO\n",
            "తమకు\tO\n",
            "ముప్ఫయి\tO\n",
            "సీట్లు\tO\n",
            "కావాలని\tB-ORG\n",
            "టీజేఎస్,\tO\n",
            "తమకు\tO\n",
            "నలభై\tO\n",
            "కావాలని\tO\n",
            "తెలుగుదేశం\tO\n",
            "కాంగ్రెస్\tO\n",
            "పార్టీకి\tO\n",
            "హెచ్చరికలు\tO\n",
            "జారీ\tO\n",
            "చేస్తున్నాయి.\tO\n",
            "లేకపోతె\tO\n",
            "తమ\tO\n",
            "దారి\tO\n",
            "తాము\tO\n",
            "చూసుకుంటామని\tB-ORG\n",
            "బెదిరింపులకు\tO\n",
            "దిగుతున్నాయి.\tO\n",
            "ఆ\tO\n",
            "రెండు\tO\n",
            "పార్టీలకే\tB-ORG\n",
            "అరవై\tI-ORG\n",
            "డ్బ్బై\tO\n",
            "స్థానాలు\tO\n",
            "ఇచ్చి\tO\n",
            "ఇక\tO\n",
            "కాంగ్రెస్\tO\n",
            "పోటీ\tO\n",
            "చేసేది\tO\n",
            "ఎన్ని\tO\n",
            "స్థానాలలో???\tO\n",
            "నవ్వు\tO\n",
            "రావడం\tO\n",
            "లేదూ?\tO\n",
            "ఎన్నికలు\tO\n",
            "అయ్యేంతవరకూ\tO\n",
            "పరస్పరం\tO\n",
            "కలహించుకోవడంలోనే\tO\n",
            "కాలక్షేపం\tO\n",
            "చేసే\tO\n",
            "మహాకూటమి\tO\n",
            "ఎన్నికల్లో\tO\n",
            "పోటీ\tO\n",
            "చేసి\tO\n",
            "విజయం\tO\n",
            "సాధించడం\tO\n",
            "అయ్యేపనేనా?\tO\n"
          ]
        }
      ],
      "source": [
        "# # let us try with some example sentences here\n",
        "# sentence='ఎన్నికల ప్రకటన వెలువడినది లగాయతు.. సీట్ల పంపకం కోసం కొట్టుకోవడమే మహాకూటమికి సరిపోతున్నది. ప్రతిరోజూ ఉదయం ఇంట్లో టిఫిన్ చెయ్యడం, గోల్కొండ రిసారట్స్‌కు వెళ్లి పిచ్చాపాటీ మాట్లాడుకుని భోజనం చెయ్యడం, ఇంటికి వెళ్లడం, మరునాడు మళ్ళీ అదే తంతు…కాంగ్రెస్ పార్టీకి కార్యకర్తలు తక్కువ, నాయకులు ఎక్కువ. సర్పంచ్ గా కూడా చేయనివాడు ముఖ్యమంత్రి కావాలనుకుంటారు ఆ పార్టీలో. అందుకే ఎప్పుడు ఎన్నికలు వచ్చినా, కాంగ్రెస్ పార్టీలో అంతర్గత యుద్ధం మొదలవుతుంది. వారికి వారే వెన్నుపోట్లు పొడుచుకుంటారు. తమకు ముప్ఫయి సీట్లు కావాలని టీజేఎస్, తమకు నలభై కావాలని తెలుగుదేశం కాంగ్రెస్ పార్టీకి హెచ్చరికలు జారీ చేస్తున్నాయి. లేకపోతె తమ దారి తాము చూసుకుంటామని బెదిరింపులకు దిగుతున్నాయి. ఆ రెండు పార్టీలకే అరవై డ్బ్బై స్థానాలు ఇచ్చి ఇక కాంగ్రెస్ పోటీ చేసేది ఎన్ని స్థానాలలో??? నవ్వు రావడం లేదూ? ఎన్నికలు అయ్యేంతవరకూ పరస్పరం కలహించుకోవడంలోనే కాలక్షేపం చేసే మహాకూటమి ఎన్నికల్లో పోటీ చేసి విజయం సాధించడం అయ్యేపనేనా?'\n",
        "# predicted_labels = get_predictions(sentence=sentence,\n",
        "#                                    tokenizer=tokenizer,\n",
        "#                                    model=model\n",
        "#                                    )\n",
        "\n",
        "# for index in range(len(sentence.split(' '))):\n",
        "#   print( sentence.split(' ')[index] + '\\t' + predicted_labels[index] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9PMc3MzBa0R"
      },
      "source": [
        "#Naampadam Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtIyB97198C7"
      },
      "source": [
        "The _Naampadam_ Dataset is a large dataset for Named Entity Recognition in 11 Indian languages.  _Naampadam_ means \"named entity\" in Sanskrit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65L_S_b_ygVq"
      },
      "outputs": [],
      "source": [
        "# Let's download the Naampadam (Indic NER) dataset\n",
        "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
        "\n",
        "lang='te'\n",
        "\n",
        "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RRPr0geXdzM",
        "outputId": "c1afa0a0-1d6d-4fc8-a363-49b4a76cac8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokens', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "small_train_dataset = raw_datasets[\"train\"].select(range(20000))\n",
        "\n",
        "# Print the length of the small dataset\n",
        "print(len(small_train_dataset))\n",
        "small_train_dataset.column_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD0wEKb-P3PV",
        "outputId": "48ab2290-09d9-46b2-a742-2797eb0c3919"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ఈ\t0\n",
            "స్మార్ట్\t0\n",
            "ఫోన్\t0\n",
            "ఇప్పటికే\t0\n",
            "ఇండోనేషియాలో\t5\n",
            "లాంచ్\t0\n",
            "అయింది\t0\n",
            ".\t0\n"
          ]
        }
      ],
      "source": [
        "# let's print an instance of dataset\n",
        "idx=1\n",
        "rec=small_train_dataset[idx]\n",
        "for w, t in zip(rec['tokens'],rec['ner_tags']):\n",
        "  print('{}\\t{}'.format(w,t))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7dLEGOJT4KA",
        "outputId": "503f6070-00d0-4b64-c645-ecd141b45cd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'ner_tags']\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": [
        "column_names = small_train_dataset.column_names\n",
        "print(column_names)\n",
        "\n",
        "features = small_train_dataset.features\n",
        "print(features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYBUl7qNULZP"
      },
      "outputs": [],
      "source": [
        "text_column_name = \"tokens\"\n",
        "label_column_name = \"ner_tags\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4f4K0B6UWcX",
        "outputId": "9f6ceb31-0f14-4084-d276-c5f2182219af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
          ]
        }
      ],
      "source": [
        "# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n",
        "\n",
        "label_list = features[label_column_name].feature.names\n",
        "\n",
        "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
        "\n",
        "print(label_to_id)\n",
        "\n",
        "num_labels = len(label_list)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQFDtTDJI0-p"
      },
      "source": [
        "# Training an NER Model with the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uI2aKUzJI5eU"
      },
      "source": [
        "We have already seen how to get predictions from fine-tuned NER model. We will now use the pre-trained IndicBERT model and fine-tune it for NER task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mo2VdmqHRXwZ"
      },
      "source": [
        "**Let** us download a pre-trained model and fine-tune it for the task of NER. We will have to use the `AutoModelForTokenClassification` class to fine-tune the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DspV280GBIGo"
      },
      "source": [
        "**Load Pre-trained Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgE-g5tjP-r7",
        "outputId": "99e61925-acdb-43dd-ec92-8c91d15740cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForTokenClassification were not initialized from the model checkpoint at ai4bharat/indic-bert and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
        "import numpy as np\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 3\n",
        "\n",
        "# Load configuration, tokenizer, and model\n",
        "config = AutoConfig.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels, finetuning_task='ner')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/indic-bert\")\n",
        "model = AutoModelForTokenClassification.from_pretrained('ai4bharat/indic-bert', num_labels=num_labels )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYqUwhZv8uCc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80401fa-8956-4706-8470-ac064d181bb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n",
            "Collecting protobuf\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-4.25.3\n"
          ]
        }
      ],
      "source": [
        "# Run the next cell if you want to use a GPU. Make sure that the Colab runtime is set accordingly\n",
        "\n",
        "#model=model.to(\"cuda\")\n",
        "!pip install --upgrade protobuf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8Xu8os_BUNZ"
      },
      "source": [
        "**Tokenize all texts and align the labels with them**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_qmsSwSVHWb"
      },
      "outputs": [],
      "source": [
        "# Tokenize all texts and align the labels with them.\n",
        "padding = \"max_length\"\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[text_column_name],\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[label_column_name]):\n",
        "        # print('=====')\n",
        "        # print('{} {}'.format(i,label)) #ak\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2b5cade2708f40e8ad6a22d65d82a3db",
            "e0980b22259344a7bfcf55c2423d78bf",
            "9500bb097bcd4dc8b4a781a7b79d4c5d",
            "a08ce1faf63d4625914de2e09b2d75ed",
            "e20ca56c734e4765bb29982d737fa620",
            "6406a0941c91424d8339c7335fb51134",
            "e522b6db78e94b0b9d233fbbdf2c97f8",
            "7bc28395a3b3402b95bc33bc22e03dc8",
            "ca0c18d07d94490eac39a032d703a00d",
            "6ca27ff0389d47be80f1e4f69a6ecf1c",
            "a413a7fa9b14437d911bd4b9a9c439db"
          ]
        },
        "id": "oEhWoszfehp4",
        "outputId": "973796ba-e7ec-4c4a-f944-07d94c58e6cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on train dataset (num_proc=6):   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b5cade2708f40e8ad6a22d65d82a3db"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "train_dataset = small_train_dataset\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGbziIF-erIM"
      },
      "outputs": [],
      "source": [
        "eval_dataset = raw_datasets[\"validation\"]\n",
        "eval_dataset = eval_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on Validation dataset\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otaDz1H7BiPC"
      },
      "source": [
        "**Create Data Collator, Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_IPs2dPfIaR"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgJ4EXYofS9f",
        "outputId": "9a543b69-d1ca-4649-f923-493871f352e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Metrics\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Unpack nested dictionaries\n",
        "    final_results = {}\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            for n, v in value.items():\n",
        "                final_results[f\"{key}_{n}\"] = v\n",
        "        else:\n",
        "            final_results[key] = value\n",
        "    return final_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4fQl8c1B1CO"
      },
      "source": [
        "**Set Training Arguments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VqwJ7ugRD7X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW2LquVNxtdP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d78058-b336-4fdb-c3da-58b62ec0f699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/290.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m245.8/290.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.28.0\n"
          ]
        }
      ],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qn30_OWzCFTM"
      },
      "source": [
        "\n",
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBz8ZFYGfakw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d755e016-847a-4164-8a8d-6d11c0d8eaac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Initialize our Trainer\n",
        "# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
        "# args.metric_for_best_model = \"f1\"\n",
        "# args.load_best_model_at_end = True\n",
        "# args.evaluation_strategy = IntervalStrategy.STEPS\n",
        "# args.eval_steps = args.save_steps\n",
        "# args.greater_is_better = True\n",
        "# Define training arguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=num_epochs,  # Set the number of epochs\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=100,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    disable_tqdm=False,\n",
        "    load_best_model_at_end=True,  # Set load_best_model_at_end to True\n",
        "    learning_rate=0.0001,  # Set the learning rate here\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvoHHBqaVbQk",
        "outputId": "3e6646b2-c0b4-4109-baab-59e425d12b2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "dispatch_batches=None,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_steps=100,\n",
              "evaluation_strategy=steps,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=False,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=0.0001,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=True,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./logs,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=10,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=linear,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=loss,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=adamw_torch,\n",
              "optim_args=None,\n",
              "output_dir=./results,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=16,\n",
              "per_device_train_batch_size=16,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard'],\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./results,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=500,\n",
              "save_strategy=steps,\n",
              "save_total_limit=2,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "split_batches=None,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.0,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "trainer.args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "JxeugXOWfzIG",
        "outputId": "95fb13d1-cad8-4ad7-ca1c-7f4a9b567544"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2800' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2800/3750 36:03 < 12:14, 1.29 it/s, Epoch 2/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc Precision</th>\n",
              "      <th>Loc Recall</th>\n",
              "      <th>Loc F1</th>\n",
              "      <th>Loc Number</th>\n",
              "      <th>Org Precision</th>\n",
              "      <th>Org Recall</th>\n",
              "      <th>Org F1</th>\n",
              "      <th>Org Number</th>\n",
              "      <th>Per Precision</th>\n",
              "      <th>Per Recall</th>\n",
              "      <th>Per F1</th>\n",
              "      <th>Per Number</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.278900</td>\n",
              "      <td>0.389858</td>\n",
              "      <td>0.710586</td>\n",
              "      <td>0.604406</td>\n",
              "      <td>0.653209</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.493237</td>\n",
              "      <td>0.527483</td>\n",
              "      <td>0.509786</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.686427</td>\n",
              "      <td>0.618263</td>\n",
              "      <td>0.650564</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.635718</td>\n",
              "      <td>0.591677</td>\n",
              "      <td>0.612907</td>\n",
              "      <td>0.877775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.419700</td>\n",
              "      <td>0.374921</td>\n",
              "      <td>0.642646</td>\n",
              "      <td>0.623563</td>\n",
              "      <td>0.632961</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.546354</td>\n",
              "      <td>0.426230</td>\n",
              "      <td>0.478873</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.652196</td>\n",
              "      <td>0.652196</td>\n",
              "      <td>0.652196</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.627287</td>\n",
              "      <td>0.587515</td>\n",
              "      <td>0.606750</td>\n",
              "      <td>0.878929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.305700</td>\n",
              "      <td>0.380523</td>\n",
              "      <td>0.706208</td>\n",
              "      <td>0.610153</td>\n",
              "      <td>0.654676</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.533199</td>\n",
              "      <td>0.511090</td>\n",
              "      <td>0.521910</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.624081</td>\n",
              "      <td>0.677645</td>\n",
              "      <td>0.649761</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.620088</td>\n",
              "      <td>0.618115</td>\n",
              "      <td>0.619100</td>\n",
              "      <td>0.880587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.282700</td>\n",
              "      <td>0.398674</td>\n",
              "      <td>0.703867</td>\n",
              "      <td>0.610153</td>\n",
              "      <td>0.653669</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.604255</td>\n",
              "      <td>0.410800</td>\n",
              "      <td>0.489093</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.689694</td>\n",
              "      <td>0.617764</td>\n",
              "      <td>0.651750</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.675771</td>\n",
              "      <td>0.563280</td>\n",
              "      <td>0.614419</td>\n",
              "      <td>0.879686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.373684</td>\n",
              "      <td>0.657063</td>\n",
              "      <td>0.677203</td>\n",
              "      <td>0.666981</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.497854</td>\n",
              "      <td>0.559306</td>\n",
              "      <td>0.526794</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.641812</td>\n",
              "      <td>0.678643</td>\n",
              "      <td>0.659714</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.607110</td>\n",
              "      <td>0.647980</td>\n",
              "      <td>0.626880</td>\n",
              "      <td>0.876225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.363807</td>\n",
              "      <td>0.689725</td>\n",
              "      <td>0.649425</td>\n",
              "      <td>0.668969</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.509044</td>\n",
              "      <td>0.569913</td>\n",
              "      <td>0.537762</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.693803</td>\n",
              "      <td>0.659182</td>\n",
              "      <td>0.676049</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.639822</td>\n",
              "      <td>0.634027</td>\n",
              "      <td>0.636911</td>\n",
              "      <td>0.886029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.321200</td>\n",
              "      <td>0.376251</td>\n",
              "      <td>0.683787</td>\n",
              "      <td>0.650383</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.556624</td>\n",
              "      <td>0.502411</td>\n",
              "      <td>0.528130</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.703725</td>\n",
              "      <td>0.622255</td>\n",
              "      <td>0.660487</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.661173</td>\n",
              "      <td>0.599021</td>\n",
              "      <td>0.628564</td>\n",
              "      <td>0.883651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.272900</td>\n",
              "      <td>0.387210</td>\n",
              "      <td>0.677483</td>\n",
              "      <td>0.659962</td>\n",
              "      <td>0.668607</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.619910</td>\n",
              "      <td>0.396336</td>\n",
              "      <td>0.483529</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.678820</td>\n",
              "      <td>0.631737</td>\n",
              "      <td>0.654433</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.667419</td>\n",
              "      <td>0.579192</td>\n",
              "      <td>0.620183</td>\n",
              "      <td>0.879253</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.316300</td>\n",
              "      <td>0.364715</td>\n",
              "      <td>0.629787</td>\n",
              "      <td>0.708812</td>\n",
              "      <td>0.666967</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.598361</td>\n",
              "      <td>0.492768</td>\n",
              "      <td>0.540455</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.645785</td>\n",
              "      <td>0.699601</td>\n",
              "      <td>0.671617</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.631667</td>\n",
              "      <td>0.649449</td>\n",
              "      <td>0.640435</td>\n",
              "      <td>0.884191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.315000</td>\n",
              "      <td>0.360287</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.603448</td>\n",
              "      <td>0.668790</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.579268</td>\n",
              "      <td>0.458052</td>\n",
              "      <td>0.511578</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.656652</td>\n",
              "      <td>0.687126</td>\n",
              "      <td>0.671544</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.660633</td>\n",
              "      <td>0.607589</td>\n",
              "      <td>0.633002</td>\n",
              "      <td>0.885561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.317400</td>\n",
              "      <td>0.344478</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.617816</td>\n",
              "      <td>0.662558</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.554939</td>\n",
              "      <td>0.482160</td>\n",
              "      <td>0.515996</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.695378</td>\n",
              "      <td>0.660679</td>\n",
              "      <td>0.677584</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.665858</td>\n",
              "      <td>0.604406</td>\n",
              "      <td>0.633646</td>\n",
              "      <td>0.888949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.284900</td>\n",
              "      <td>0.361858</td>\n",
              "      <td>0.650679</td>\n",
              "      <td>0.688697</td>\n",
              "      <td>0.669148</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.602454</td>\n",
              "      <td>0.473481</td>\n",
              "      <td>0.530238</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.668159</td>\n",
              "      <td>0.670160</td>\n",
              "      <td>0.669158</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.649618</td>\n",
              "      <td>0.624969</td>\n",
              "      <td>0.637056</td>\n",
              "      <td>0.886101</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.251200</td>\n",
              "      <td>0.355930</td>\n",
              "      <td>0.704268</td>\n",
              "      <td>0.663793</td>\n",
              "      <td>0.683432</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.563278</td>\n",
              "      <td>0.523626</td>\n",
              "      <td>0.542729</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.691061</td>\n",
              "      <td>0.659681</td>\n",
              "      <td>0.675006</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.662523</td>\n",
              "      <td>0.626193</td>\n",
              "      <td>0.643846</td>\n",
              "      <td>0.889237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.322100</td>\n",
              "      <td>0.357890</td>\n",
              "      <td>0.659813</td>\n",
              "      <td>0.676245</td>\n",
              "      <td>0.667928</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.539713</td>\n",
              "      <td>0.543877</td>\n",
              "      <td>0.541787</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.651000</td>\n",
              "      <td>0.698104</td>\n",
              "      <td>0.673730</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.625938</td>\n",
              "      <td>0.653366</td>\n",
              "      <td>0.639358</td>\n",
              "      <td>0.885993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.287000</td>\n",
              "      <td>0.359024</td>\n",
              "      <td>0.611570</td>\n",
              "      <td>0.708812</td>\n",
              "      <td>0.656610</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.533149</td>\n",
              "      <td>0.558341</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.674611</td>\n",
              "      <td>0.692116</td>\n",
              "      <td>0.683251</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.621783</td>\n",
              "      <td>0.662424</td>\n",
              "      <td>0.641460</td>\n",
              "      <td>0.886606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.249500</td>\n",
              "      <td>0.363123</td>\n",
              "      <td>0.711306</td>\n",
              "      <td>0.620690</td>\n",
              "      <td>0.662916</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.513986</td>\n",
              "      <td>0.567020</td>\n",
              "      <td>0.539202</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.708423</td>\n",
              "      <td>0.654691</td>\n",
              "      <td>0.680498</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.652163</td>\n",
              "      <td>0.623745</td>\n",
              "      <td>0.637638</td>\n",
              "      <td>0.886642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.202100</td>\n",
              "      <td>0.371449</td>\n",
              "      <td>0.723810</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.687783</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.604326</td>\n",
              "      <td>0.458052</td>\n",
              "      <td>0.521119</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.691922</td>\n",
              "      <td>0.688124</td>\n",
              "      <td>0.690018</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.681525</td>\n",
              "      <td>0.621297</td>\n",
              "      <td>0.650019</td>\n",
              "      <td>0.889490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.259000</td>\n",
              "      <td>0.353893</td>\n",
              "      <td>0.740363</td>\n",
              "      <td>0.625479</td>\n",
              "      <td>0.678089</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.538533</td>\n",
              "      <td>0.559306</td>\n",
              "      <td>0.548723</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.692347</td>\n",
              "      <td>0.677146</td>\n",
              "      <td>0.684662</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.660883</td>\n",
              "      <td>0.634027</td>\n",
              "      <td>0.647176</td>\n",
              "      <td>0.889598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>0.362030</td>\n",
              "      <td>0.654344</td>\n",
              "      <td>0.678161</td>\n",
              "      <td>0.666040</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.562189</td>\n",
              "      <td>0.544841</td>\n",
              "      <td>0.553379</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.691623</td>\n",
              "      <td>0.659182</td>\n",
              "      <td>0.675013</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.648987</td>\n",
              "      <td>0.635006</td>\n",
              "      <td>0.641920</td>\n",
              "      <td>0.888120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.228700</td>\n",
              "      <td>0.354906</td>\n",
              "      <td>0.688822</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.671576</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.526412</td>\n",
              "      <td>0.557377</td>\n",
              "      <td>0.541452</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.680158</td>\n",
              "      <td>0.687625</td>\n",
              "      <td>0.683871</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.641244</td>\n",
              "      <td>0.646267</td>\n",
              "      <td>0.643745</td>\n",
              "      <td>0.887327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.277500</td>\n",
              "      <td>0.351485</td>\n",
              "      <td>0.702321</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.684029</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.581699</td>\n",
              "      <td>0.514947</td>\n",
              "      <td>0.546292</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.685315</td>\n",
              "      <td>0.684631</td>\n",
              "      <td>0.684973</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.665303</td>\n",
              "      <td>0.636965</td>\n",
              "      <td>0.650825</td>\n",
              "      <td>0.890247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.303200</td>\n",
              "      <td>0.345939</td>\n",
              "      <td>0.720604</td>\n",
              "      <td>0.639847</td>\n",
              "      <td>0.677829</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.545709</td>\n",
              "      <td>0.564127</td>\n",
              "      <td>0.554765</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.724947</td>\n",
              "      <td>0.678643</td>\n",
              "      <td>0.701031</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.674323</td>\n",
              "      <td>0.639657</td>\n",
              "      <td>0.656533</td>\n",
              "      <td>0.891112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.189200</td>\n",
              "      <td>0.364228</td>\n",
              "      <td>0.674081</td>\n",
              "      <td>0.667625</td>\n",
              "      <td>0.670837</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.539262</td>\n",
              "      <td>0.549662</td>\n",
              "      <td>0.544413</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.669747</td>\n",
              "      <td>0.687126</td>\n",
              "      <td>0.678325</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.637569</td>\n",
              "      <td>0.647246</td>\n",
              "      <td>0.642371</td>\n",
              "      <td>0.887760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.332400</td>\n",
              "      <td>0.350113</td>\n",
              "      <td>0.639616</td>\n",
              "      <td>0.702107</td>\n",
              "      <td>0.669406</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.569322</td>\n",
              "      <td>0.558341</td>\n",
              "      <td>0.563778</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.672504</td>\n",
              "      <td>0.709082</td>\n",
              "      <td>0.690308</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.639149</td>\n",
              "      <td>0.669033</td>\n",
              "      <td>0.653750</td>\n",
              "      <td>0.890643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.230100</td>\n",
              "      <td>0.348323</td>\n",
              "      <td>0.707724</td>\n",
              "      <td>0.649425</td>\n",
              "      <td>0.677323</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.603795</td>\n",
              "      <td>0.521697</td>\n",
              "      <td>0.559752</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.685854</td>\n",
              "      <td>0.701597</td>\n",
              "      <td>0.693636</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.672387</td>\n",
              "      <td>0.642595</td>\n",
              "      <td>0.657154</td>\n",
              "      <td>0.894103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.120600</td>\n",
              "      <td>0.365585</td>\n",
              "      <td>0.717256</td>\n",
              "      <td>0.660920</td>\n",
              "      <td>0.687936</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.570571</td>\n",
              "      <td>0.549662</td>\n",
              "      <td>0.559921</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.699000</td>\n",
              "      <td>0.697605</td>\n",
              "      <td>0.698302</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.671043</td>\n",
              "      <td>0.650673</td>\n",
              "      <td>0.660701</td>\n",
              "      <td>0.893022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.174500</td>\n",
              "      <td>0.363967</td>\n",
              "      <td>0.688541</td>\n",
              "      <td>0.673372</td>\n",
              "      <td>0.680872</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.553889</td>\n",
              "      <td>0.569913</td>\n",
              "      <td>0.561787</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.726190</td>\n",
              "      <td>0.669661</td>\n",
              "      <td>0.696781</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.669715</td>\n",
              "      <td>0.645288</td>\n",
              "      <td>0.657275</td>\n",
              "      <td>0.891328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.186000</td>\n",
              "      <td>0.365497</td>\n",
              "      <td>0.655485</td>\n",
              "      <td>0.692529</td>\n",
              "      <td>0.673498</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.526129</td>\n",
              "      <td>0.572806</td>\n",
              "      <td>0.548476</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.685854</td>\n",
              "      <td>0.701597</td>\n",
              "      <td>0.693636</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.635918</td>\n",
              "      <td>0.666585</td>\n",
              "      <td>0.650890</td>\n",
              "      <td>0.889886</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory ./results/checkpoint-2500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ],
      "source": [
        "train_result = trainer.train()\n",
        "metrics = train_result.metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd97CJLvf3-x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "16962dd6-fdea-4e1b-c0a8-130adc694a61"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='169' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 00:29]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =       2.24\n",
            "  eval_LOC_f1             =     0.6773\n",
            "  eval_LOC_number         =       1044\n",
            "  eval_LOC_precision      =     0.7077\n",
            "  eval_LOC_recall         =     0.6494\n",
            "  eval_ORG_f1             =     0.5598\n",
            "  eval_ORG_number         =       1037\n",
            "  eval_ORG_precision      =     0.6038\n",
            "  eval_ORG_recall         =     0.5217\n",
            "  eval_PER_f1             =     0.6936\n",
            "  eval_PER_number         =       2004\n",
            "  eval_PER_precision      =     0.6859\n",
            "  eval_PER_recall         =     0.7016\n",
            "  eval_loss               =     0.3483\n",
            "  eval_overall_accuracy   =     0.8941\n",
            "  eval_overall_f1         =     0.6572\n",
            "  eval_overall_precision  =     0.6724\n",
            "  eval_overall_recall     =     0.6426\n",
            "  eval_runtime            = 0:00:31.07\n",
            "  eval_samples_per_second =     86.889\n",
            "  eval_steps_per_second   =      5.439\n"
          ]
        }
      ],
      "source": [
        "\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = raw_datasets['test']\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "64lElCowtHVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test_dataset)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "4i6LjCGcuDmf",
        "outputId": "ab218f8a-e4d1-4e72-840c-d4e70c7df7e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 01:24]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =       2.24\n",
            "  eval_LOC_f1             =     0.7075\n",
            "  eval_LOC_number         =        483\n",
            "  eval_LOC_precision      =      0.801\n",
            "  eval_LOC_recall         =     0.6335\n",
            "  eval_ORG_f1             =     0.6178\n",
            "  eval_ORG_number         =        263\n",
            "  eval_ORG_precision      =     0.6275\n",
            "  eval_ORG_recall         =     0.6084\n",
            "  eval_PER_f1             =     0.7644\n",
            "  eval_PER_number         =        609\n",
            "  eval_PER_precision      =     0.7753\n",
            "  eval_PER_recall         =     0.7537\n",
            "  eval_loss               =     0.2862\n",
            "  eval_overall_accuracy   =     0.9134\n",
            "  eval_overall_f1         =     0.7159\n",
            "  eval_overall_precision  =     0.7526\n",
            "  eval_overall_recall     =     0.6827\n",
            "  eval_runtime            = 0:00:09.74\n",
            "  eval_samples_per_second =     86.883\n",
            "  eval_steps_per_second   =      5.437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_BXkj75Mt1K",
        "outputId": "b5fa09d9-c902-44ce-8994-72e8653cad25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['tokens', 'ner_tags', 'input_ids', 'token_type_ids', 'attention_mask', 'labels'],\n",
            "    num_rows: 847\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-k4EixXeI7h"
      },
      "source": [
        "##Question 4:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXR3Ukn0ex4M"
      },
      "outputs": [],
      "source": [
        "data = [\n",
        "    {\n",
        "        \"tokens\": [\n",
        "            \"అయితే\", \"ఈ\", \"సారి\", \"అనూహ్యంగా\", \"కోటి\", \"యాభై\", \"లక్షల\",\n",
        "            \"పలకడంతో\", \"ఆ\", \"డబ్బును\", \"ఏం\", \"చేయాలో\", \"ఇంకా\", \"నిర్ణయించుకోలేదని\",\n",
        "            \"గోయట్\", \"చెప్పుకొచ్చాడు\"\n",
        "        ],\n",
        "        \"ner_tags\": [\n",
        "            0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0\n",
        "        ]\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your function expects \"text\" for the text data and \"labels\" for the labels\n",
        "# For testing, you might not need actual labels, but let's include them for the sake of format\n",
        "\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lEF3WJxPQyjy",
        "outputId": "45dd3976-fb9d-43e5-aa8c-e533b5b715a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': ['అయితే', 'ఈ', 'సారి', 'అనూహ్యంగా', 'కోటి', 'యాభై', 'లక్షల', 'పలకడంతో', 'ఆ', 'డబ్బును', 'ఏం', 'చేయాలో', 'ఇంకా', 'నిర్ణయించుకోలేదని', 'గోయట్', 'చెప్పుకొచ్చాడు'], 'ner_tags': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, ClassLabel, Value, Sequence\n",
        "\n",
        "# Assuming your data is structured like this:\n",
        "data = [\n",
        "{   \"tokems\": [     \"అయితే\",     \"ఈ\",     \"సారి\",     \"అనూహ్యంగా\",     \"కోటి\",     \"యాభై\",     \"లక్షల\",     \"పలకడంతో\",     \"ఆ\",     \"డబ్బును\",     \"ఏం\",     \"చేయాలో\",     \"ఇంకా\",     \"నిర్ణయించుకోలేదని\",     \"గోయట్\",     \"చెప్పుకొచ్చాడు\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "{   \"tokems\": [     \"ప్రజల\",     \"మనోభావాలు,\",     \"ఎమోషన్స్\",     \"కి\",     \"అంతగా\",     \"ప్రాముఖ్యత\",     \"ఇవ్వకుండా\",     \"తానుఅనుకున్న\",     \"పనులు\",     \"చక్కబెట్టేవారు\",   \" .\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",  \"O\"   ] },\n",
        "{   \"tokems\": [     \"అప్పుడు,\",     \"మీరు\",     \"చివరకు\",     \"చూస్తున్న\",     \"పెరుగుదల\",     \"అలవాటు\",     \"రకం\",     \"ప్రోత్సహించడానికి\",     \"న్యాయమైన\",     \"కట్స్\",     \"తయారు\",  \".\"  ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\", \"O\"   ] },\n",
        "{   \"tokems\": [ \"ఎన్నికల\", \"ప్రకటన\", \"వెలువడినది\", \"లగాయతు\", \"సీట్ల\", \"పంపకం\", \"కోసం\", \"కొట్టుకోవడమే\", \"మహాకూటమికి\", \"సరిపోతున్నది\", \"ప్రతిరోజూ\", \"ఉదయం\", \"ఇంట్లో\", \"టిఫిన్\", \"చెయ్యడం\", \"గోల్కొండ\", \"రిసారట్స్కు\", \"వెళ్లి\", \"పిచ్చాపాటీ\", \"మాట్లాడుకుని\", \"భోజనం\", \"చెయ్యడం\", \"ఇంటికి\", \"వెళ్లడం\", \"మరునాడు\", \"మళ్ళీ\", \"అదే\", \"తంతు\", \"కాంగ్రెస్\", \"పార్టీకి\", \"కార్యకర్తలు\", \"తక్కువ\", \"నాయకులు\", \"ఎక్కువ\", \"సర్పంచ్\", \"గా\", \"కూడా\", \"చేయనివాడు\", \"ముఖ్యమంత్రి\", \"కావాలనుకుంటారు\", \"ఆ\", \"పార్టీలో\", \"అందుకే\", \"ఎప్పుడు\", \"ఎన్నికలు\", \"వచ్చినా\", \"కాంగ్రెస్\", \"పార్టీలో\", \"అంతర్గత\", \"యుద్ధం\", \"మొదలవుతుంది\", \"వారికి\", \"వారే\", \"వెన్నుపోట్లు\", \"పొడుచుకుంటారు\", \"తమకు\", \"ముప్ఫయి\", \"సీట్లు\", \"కావాలని\", \"టీజేఎస్\", \"తమకు\", \"నలభై\", \"కావాలని\", \"తెలుగుదేశం\", \"కాంగ్రెస్\", \"పార్టీకి\", \"హెచ్చరికలు\", \"జారీ\", \"చేస్తున్నాయి\", \"లేకపోతె\", \"తమ\", \"దారి\", \"తాము\", \"చూసుకుంటామని\", \"బెదిరింపులకు\", \"దిగుతున్నాయి\", \"ఆ\", \"రెండు\", \"పార్టీలకే\", \"అరవై\", \"డ్బ్బై\", \"స్థానాలు\", \"ఇచ్చి\", \"ఇక\", \"కాంగ్రెస్\", \"పోటీ\", \"చేసేది\", \"ఎన్ని\", \"స్థానాలలో\", \"నవ్వు\", \"రావడం\", \"లేదూ\", \"ఎన్నికలు\", \"అయ్యేంతవరకూ\", \"పరస్పరం\", \"కలహించుకోవడంలోనే\", \"కాలక్షేపం\", \"మహాకూటమి\", \"ఎన్నికల్లో\", \"పోటీ\", \"చేసి\", \"విజయం\", \"సాధించడం\", \"అయ్యేపనేనా\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"B-ORG\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokems\": [ \"మెగా\", \"పవర్\", \"స్టార్\", \"రామ్\", \"చరణ్\", \",\", \"ఊరమాస్\", \"డైరెక్టర్\", \"బోయపాటి\", \"శ్రీను\", \"కాంబినేషన్‌లో\", \",\", \"ఫ్యామిలీ\", \",\", \"లవ్\", \"అండ్\", \"యాక్షన్\", \"ఎంటర్‌టైనర్‌గా\", \"రూపొందిన\", \"వినయ\", \"విధేయ\", \"రామ్\", \",\", \"జనవరి\", \"11న\", \"వరల్డ్\", \"వైడ్\", \"గ్రాండ్\", \"రిలీజ్‌కి\", \"రెఢీ\", \"అయిపోయింది\", \".\", \"డి.వి.వి.\", \"దానయ్య\", \"నిర్మించగా\", \",\", \"కైరా\", \"అద్వాణీ\", \"హీరోయిన్‌గా\", \"నటించింది\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\" ] },\n",
        "{ \"tokems\": [ \"అది,\", \"పొందుటకు\", \",\",  \"మేము\", \"ప్రధాన\", \"ద్వారం\", \"నుండి\", \"కుడి\", \"చెయ్యి\", \"మరియు\", \"నిరంతరం\", \"పెరుగుతుంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "  { \"tokems\": [ \"లోతైన\", \"సమావేశంలో\", \",\", \"సారాంశం\", \"మానవ\", \"శరీరంలో\", \"నుండి\", \"వేరు\", \",\", \"అస్తిత్వ\", \"మరణం\", \"అని\", \"పిలువబడుతుంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokems\": [ \"చాటుసాహిత్యంలో\", \"తరచూ\", \"కనిపించే\", \"లక్షణం\", \"–\", \"పద్యాల\", \"గురించీ\", \",\", \"కవుల\", \"గురించీ\", \"జనవ్యవహారంలో\", \"వ్యాప్తమైయ్యే\", \"కథలు\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\",  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokems\": [ \"బ్రేకింగ్\", \":\", \"మళ్ళీ\", \"వైసీపీలోకి\", \"ఎంట్రీ\", \"ఇస్తున్న\", \"కీలక\", \"నేత\", \"..\", \"షాక్‌లో\", \"టీడీపీ\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\"] },\n",
        " { \"tokems\": [ \"ప్రామాణిక\", \"బ్యాంకు\", \"రుణ\", \"జారీ\", \"కాకుండా\", \",\", \"క్రెడిట్\", \"యొక్క\", \"లైన్\", \"ఆర్థిక\", \"సంస్థల\", \"రుణగ్రహీతలు\", \"మరింత\", \"ఆకర్షణీయంగా\", \",\", \"అలాగే\", \"ఉంది\", \".\" ], \"ner_tags\": [ \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokems\": [ \"వారి\", \"ప్రకాశవంతమైన\", \"నక్షత్రాలు\", \"సిరియస్\", \"మరియు\", \"Procyon\", \"ఏ\", \"ఇతర\", \"తో\", \"తికమక\", \"కష్టం\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokems\": [ \"పీటర్స్బర్గ్\", \"పతనం\", \"తరువాత\", \"లీ\", \"యొక్క\", \"వెనుకవైపు\", \"ఉన్న\", \"సైనికదళాన్ని\", \"కొనసాగించడంతో\", \",\",  \"రైట్\", \"మరియు\", \"VI\", \"కార్ప్స్\", \"మళ్లీ\", \"షెరిడాన్\", \"దిశగా\", \"వచ్చారు\", \".\" ], \"ner_tags\": [ \"B-PER\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"B-PER\",  \"O\", \"B-LOC\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokems\": [ \"దానిపై\", \"హైడ్\", \"ప్రదర్శన\", \"లక్షణాలు\", \"ఒక\", \"ప్రాథమిక\", \"వివరణ\", \"తో\", \"ప్రారంభం\", \"కావాలి\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokems\": [ \"మోరెనా\", \"జిల్లా\", \"జౌరా\", \"ప్రాంతంలో\", \"జరిగిన\", \"ఒక\", \"ఎన్నికల\", \"సభలో\", \"రాహుల్\", \"మాట్లాడుతూ\", \"ఎంజే\", \"అక్బర్‌పై\", \"పలువురు\", \"మహిళా\", \"జర్నలిస్టులు\", \"చేసిన\", \"లైంగిక\", \"దాడి\", \"ఆరోపణలను\", \"దృష్టిలో\", \"పెట్టుకొని\", \"మోదీ\", \"ప్రభుత్వాన్ని\", \"నిలదీశారు\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\" ] },\n",
        "\n",
        " #  { \"tokems\": [ \"కాన్స్టాంటినోపుల్లో\", \"బోహెంండ్\", \"ముఖ్యంగా\", \"స్వాగతం\", \"లేదు\", \"ఎందుకంటే\", \"అతని\", \"తండ్రి\", \",\", \"రాబర్ట్\", \"గైకార్డ్\", \",\", \"బైజాంటైన్\", \"సామ్రాజ్యాన్ని\", \"ఆక్రమించి\", \",\", \"డియర్హచ్యూమ్\", \"మరియు\", \"కోర్ఫు\", \"నగరాలను\", \"స్వాధీనం\", \"చేసుకున్నాడు\", \".\" ], \"ner_tags\": [ 6, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 6, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0 ] },\n",
        " #   { \"tokems\": [ \"శిఖరం\", \"(\", \"ఉత్తమ\", \"సమయం\", \"-\", \"సాయంత్రం\", \"ముఖ్యంగా\", \"“\", \"వర్షం\", \"కింద\", \"“\", \")\", \"యొక్క\", \"వేడి\", \"మానుకోండి\", \";\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #  { \"tokems\": [ \"ఏదైనా\", \"ఒక\", \"నీటి\", \"పారుదల\", \"ప్రాజెక్టుకు\", \"జాతీయ\", \"హోదాను\", \"ఇవ్వాలని\", \"కోరే\", \"అవకాశం\", \"ఉంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #{ \"tokems\": [ \"ప్రైవేట్స్‌\", \"పోల్స్‌ను\", \"బట్టి\", \"చూస్తే\", \"వితిక\", \"పరిస్థితి\", \"మాత్రం\", \"దారుణంగా\", \"ఉన్నట్లు\", \"తెలుస్తోంది\", \".\" ], \"ner_tags\": [ 0,0,0,0,0,0,0,0,0,0,0 ] },\n",
        " # { \"tokems\": [ \"బంగ్లా\", \"ఓపెనర్\", \"షాద్‌మన్‌\", \"ఇస్లామ్‌.\", \"(\", \"29\", \")\", \"ఫర్వాలేదనిపించగా\", \"...\", \"మరో\", \"ఓపెనర్\", \"ఇమ్రుల్‌\", \"(\", \"4\", \")\", \"నిరాశపరిచాడు\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # { \"tokems\": [ \"అయితే\", \"వాటికి\", \"హైనెక్‌\", \"బ్లవుజులు\", \",\", \"కాలర్స్‌\", \",\", \"ఫుల్‌స్లీవ్స్‌\", \",\", \"క్లోజ్డ్‌\", \",\", \"బోట్‌\", \",\", \"బ్యాక్‌హైనెక్\", \"‌,\", \"ఫ్రంట్‌\", \"రౌండ్‌నెక్‌\", \"బ్లవుజ్‌లు\", \"బాగుంటాయి\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # {    \"tokems\": [     \"4\",     \")\",     \"పైన\",     \"చెప్పిన\",     \"వి\",     \"అనగా\",     \"కలిపి\",     \"పెట్టుకున్న\",     \"రవ్వ\",     \",\",     \"ఉడికించిన\",     \"ఆలూ\",     \",\",     \"కట్\",     \"చెసి\",     \"పెట్టకున్నవి\",     \"అన్ని\",     \"ఇంకా\",     \"జిలకర్ర\",     \",\",     \"ఉప్పు\",     \"రుచి\",     \"కి\",     \"సరిపడ\",     \".\",     \"వెసి\",     \"ముద్ద\",     \"లా\",     \"కలుపుకోవాలీ\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] },\n",
        " #{   \"tokems\": [     \"సినిమాలో\",     \"కంటెంట్\",     \"అంతంతమాత్రమే\",     \"అయినప్పటికీ\",     \"..\",     \"ఈ\",     \"మాత్రం\",     \"వసూళ్లు\",     \"వచ్చాయంటే\",     \"అది\",     \"ఎన్టీఆర్\",     \"పెర్ఫామెన్స్‌\",     \"వల్లే\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "  #{   \"tokems\": [     \"‘\",     \"స్టార్స్\",     \"‌’\",     \"(\",     \"స్కీమ్‌\",     \"ఫర్‌\",     \"ట్రాన్స్‌ఫర్మేషన్‌\",     \"అండ్‌\",     \"అడ్వాన్స్‌డ్‌\",     \"రీసెర్చ్‌\",     \"ఇన్‌\",     \"బేసిక్‌\",     \"సైన్సెస్\",     \")\",     \",\",     \"ఐఐఎస్‌సీ\",     \"బెంగళూరు\",     \"ద్వారా\",     \"అధ్యయన\",     \"కార్యక్రమాలను\",     \"మంజూరు\",     \"చేస్తున్నారు\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"B-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"O\",     \"O\",     \"B-ORG\",     \"B-LOC\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] }\n",
        "    # More records...\n",
        "]\n",
        "\n",
        "# Transform your list of dictionaries into the expected format\n",
        "transformed_data = {\n",
        "    \"tokems\": [item[\"tokems\"] for item in data],\n",
        "    \"ner_tags\": [item[\"ner_tags\"] for item in data],\n",
        "}\n",
        "\n",
        "# Define the features of your dataset, aligning with your manual data structure\n",
        "features = Features({\n",
        "    'tokems': Sequence(feature=Value(dtype='string')),\n",
        "    'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']))\n",
        "})\n",
        "\n",
        "# Create a Dataset object from your transformed data\n",
        "question1_data = Dataset.from_dict(transformed_data, features=features)\n",
        "\n",
        "# Now you can access column_names and features just like your training dataset\n",
        "column_names = question1_data.column_names\n",
        "print(column_names)\n",
        "\n",
        "dataset_features = question1_data.features\n",
        "print(dataset_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7WVQ7A4uQ_AP",
        "outputId": "65a771a7-a609-4709-e298-79b1976340d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokems', 'ner_tags']\n",
            "{'tokems': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(question1_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiD_t6gJTgJv",
        "outputId": "af79507f-0cc9-4f15-ad48-c06f45688c40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['tokems', 'ner_tags'],\n",
            "    num_rows: 23\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = question1_data\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9834c375afdb4326962de32d180b999e",
            "ca346fd5730447edad1a83ef6bac409b",
            "954de9ee21564c128ce8202ec7d6fd20",
            "b07cdd9a3ff0446abea0506377f96393",
            "03e3a66e4ffe4fc7918591ae9a998ec4",
            "14308e960b5942158212260ea32d0d37",
            "0791c108af88471f90db7be67a564767",
            "c3f31a5dcbf248558d2b729de86f0efc",
            "b71157aa405e4fbdbe79835a4aec3373",
            "239ec0d359dc48a7bf39abdccce7e6eb",
            "933e226291454a5faffbc3136008bb94"
          ]
        },
        "id": "j03EFU2YcIkG",
        "outputId": "e0fde647-7bb6-4f1a-a47c-48f9067dc99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on train dataset (num_proc=6):   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9834c375afdb4326962de32d180b999e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test_dataset)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "RHq9j-AJcil8",
        "outputId": "24c935b8-e4fe-481d-96bf-76904e2a9d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='224' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 1:45:20]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =       2.24\n",
            "  eval_LOC_f1             =     0.5714\n",
            "  eval_LOC_number         =          5\n",
            "  eval_LOC_precision      =        1.0\n",
            "  eval_LOC_recall         =        0.4\n",
            "  eval_ORG_f1             =     0.1429\n",
            "  eval_ORG_number         =         11\n",
            "  eval_ORG_precision      =     0.3333\n",
            "  eval_ORG_recall         =     0.0909\n",
            "  eval_PER_f1             =     0.4545\n",
            "  eval_PER_number         =         14\n",
            "  eval_PER_precision      =      0.625\n",
            "  eval_PER_recall         =     0.3571\n",
            "  eval_loss               =     0.4211\n",
            "  eval_overall_accuracy   =     0.9128\n",
            "  eval_overall_f1         =     0.3721\n",
            "  eval_overall_precision  =     0.6154\n",
            "  eval_overall_recall     =     0.2667\n",
            "  eval_runtime            = 0:00:00.20\n",
            "  eval_samples_per_second =     68.868\n",
            "  eval_steps_per_second   =      4.919\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2b5cade2708f40e8ad6a22d65d82a3db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e0980b22259344a7bfcf55c2423d78bf",
              "IPY_MODEL_9500bb097bcd4dc8b4a781a7b79d4c5d",
              "IPY_MODEL_a08ce1faf63d4625914de2e09b2d75ed"
            ],
            "layout": "IPY_MODEL_e20ca56c734e4765bb29982d737fa620"
          }
        },
        "e0980b22259344a7bfcf55c2423d78bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6406a0941c91424d8339c7335fb51134",
            "placeholder": "​",
            "style": "IPY_MODEL_e522b6db78e94b0b9d233fbbdf2c97f8",
            "value": "Running tokenizer on train dataset (num_proc=6): 100%"
          }
        },
        "9500bb097bcd4dc8b4a781a7b79d4c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bc28395a3b3402b95bc33bc22e03dc8",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca0c18d07d94490eac39a032d703a00d",
            "value": 20000
          }
        },
        "a08ce1faf63d4625914de2e09b2d75ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ca27ff0389d47be80f1e4f69a6ecf1c",
            "placeholder": "​",
            "style": "IPY_MODEL_a413a7fa9b14437d911bd4b9a9c439db",
            "value": " 20000/20000 [00:15&lt;00:00, 2110.16 examples/s]"
          }
        },
        "e20ca56c734e4765bb29982d737fa620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6406a0941c91424d8339c7335fb51134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e522b6db78e94b0b9d233fbbdf2c97f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc28395a3b3402b95bc33bc22e03dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca0c18d07d94490eac39a032d703a00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6ca27ff0389d47be80f1e4f69a6ecf1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a413a7fa9b14437d911bd4b9a9c439db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9834c375afdb4326962de32d180b999e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca346fd5730447edad1a83ef6bac409b",
              "IPY_MODEL_954de9ee21564c128ce8202ec7d6fd20",
              "IPY_MODEL_b07cdd9a3ff0446abea0506377f96393"
            ],
            "layout": "IPY_MODEL_03e3a66e4ffe4fc7918591ae9a998ec4"
          }
        },
        "ca346fd5730447edad1a83ef6bac409b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14308e960b5942158212260ea32d0d37",
            "placeholder": "​",
            "style": "IPY_MODEL_0791c108af88471f90db7be67a564767",
            "value": "Running tokenizer on train dataset (num_proc=6): 100%"
          }
        },
        "954de9ee21564c128ce8202ec7d6fd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3f31a5dcbf248558d2b729de86f0efc",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b71157aa405e4fbdbe79835a4aec3373",
            "value": 14
          }
        },
        "b07cdd9a3ff0446abea0506377f96393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_239ec0d359dc48a7bf39abdccce7e6eb",
            "placeholder": "​",
            "style": "IPY_MODEL_933e226291454a5faffbc3136008bb94",
            "value": " 14/14 [00:00&lt;00:00, 34.73 examples/s]"
          }
        },
        "03e3a66e4ffe4fc7918591ae9a998ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14308e960b5942158212260ea32d0d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0791c108af88471f90db7be67a564767": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3f31a5dcbf248558d2b729de86f0efc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71157aa405e4fbdbe79835a4aec3373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "239ec0d359dc48a7bf39abdccce7e6eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "933e226291454a5faffbc3136008bb94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}