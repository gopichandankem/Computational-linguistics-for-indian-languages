{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2232ff5a7d274706a74bbaf1b6bdbadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4a35520eb1d4550808d1c20930d4e1b",
              "IPY_MODEL_fe67a50711d449ff91362506fffd27f1",
              "IPY_MODEL_c19bf97e8999485b9074115e122b28ed"
            ],
            "layout": "IPY_MODEL_b2dfa01082744d19b72dc9d035755211"
          }
        },
        "c4a35520eb1d4550808d1c20930d4e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652736cc03454854ad10c47657edbf1f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eeafacca2a144d20864d36ddb20a0913",
            "value": "Runningâ€‡tokenizerâ€‡onâ€‡trainâ€‡datasetâ€‡(num_proc=6):â€‡100%"
          }
        },
        "fe67a50711d449ff91362506fffd27f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4051e27c50544d6bb6b2416518aa5ac6",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87b84eb3406545b3a96b0835cc2800f3",
            "value": 14
          }
        },
        "c19bf97e8999485b9074115e122b28ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c118ba6bc38b45a3858d28a2eb20a515",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2e44032a27d144acb3bf98b5255b4d81",
            "value": "â€‡14/14â€‡[00:00&lt;00:00,â€‡76.82â€‡examples/s]"
          }
        },
        "b2dfa01082744d19b72dc9d035755211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "652736cc03454854ad10c47657edbf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeafacca2a144d20864d36ddb20a0913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4051e27c50544d6bb6b2416518aa5ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b84eb3406545b3a96b0835cc2800f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c118ba6bc38b45a3858d28a2eb20a515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e44032a27d144acb3bf98b5255b4d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAD5DKqk4rYG",
        "outputId": "d9737e54-7f4e-42f7-cff2-6dc534d2bd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip3 install sentencepiece\n",
        "!pip3 install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary classes and initialize the tokenizer and model.\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJlT6sik4yLm",
        "outputId": "c5a5cd3d-bb5a-4f0b-8fd0-886602ab6d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions( sentence, tokenizer, model ):\n",
        "  # Let us first tokenize the sentence - split words into subwords\n",
        "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # we will send the tokenized sentence to the model to get predictions\n",
        "    logits = model(**tok_sentence).logits.argmax(-1)\n",
        "\n",
        "    # We will map the maximum predicted class id with the class label\n",
        "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
        "\n",
        "    predicted_labels = []\n",
        "\n",
        "    previous_token_id = 0\n",
        "    # we need to assign the named entity label to the head word and not the following sub-words\n",
        "    word_ids = tok_sentence.word_ids()\n",
        "    for word_index in range(len(word_ids)):\n",
        "        if word_ids[word_index] == None:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        elif word_ids[word_index] == previous_token_id:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        else:\n",
        "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
        "            previous_token_id = word_ids[word_index]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "yoiu2P1o40FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's download the Naampadam (Indic NER) dataset\n",
        "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
        "\n",
        "lang='te'\n",
        "\n",
        "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
      ],
      "metadata": {
        "id": "aW6w52sn42Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = raw_datasets[\"train\"].select(range(20000))\n",
        "\n",
        "# Print the length of the small dataset\n",
        "print(len(small_train_dataset))\n",
        "small_train_dataset.column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c8UIMn543j5",
        "outputId": "7606d1a4-6383-48f5-bbff-d3c33a1c2e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokens', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's print an instance of dataset\n",
        "idx=10\n",
        "rec=small_train_dataset[idx]\n",
        "for w, t in zip(rec['tokens'],rec['ner_tags']):\n",
        "  print('{}\\t{}'.format(w,t))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUkCW8yw47HQ",
        "outputId": "f8ab5f1c-b557-4b86-b4ec-a68d3edb93f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "à°ˆ\t0\n",
            "à°¸à°¿à°¨à°¿à°®à°¾\t0\n",
            "à°•à±‚à°¡à°¾\t0\n",
            "à°®à°‚à°šà°¿\t0\n",
            "à°¹à°¿à°Ÿà±\t0\n",
            "à°…à°¯à°¿à°¨à°¦à°¿\t0\n",
            ".\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = small_train_dataset.column_names\n",
        "print(column_names)\n",
        "\n",
        "features = small_train_dataset.features\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBIEk5Ey49ji",
        "outputId": "27841154-8c2d-4778-e4c1-4915ff6223db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'ner_tags']\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_column_name = \"tokens\"\n",
        "label_column_name = \"ner_tags\""
      ],
      "metadata": {
        "id": "MKTNyGWl5cJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n",
        "\n",
        "label_list = features[label_column_name].feature.names\n",
        "\n",
        "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
        "\n",
        "print(label_to_id)\n",
        "\n",
        "num_labels = len(label_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAEqyhM5eo0",
        "outputId": "d7e7a000-f178-4dc4-da42-fe46cd7e15bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the next cell if you want to use a GPU. Make sure that the Colab runtime is set accordingly\n",
        "\n",
        "model=model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PN6-zrMq5ga-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk0VjAhh5n1l",
        "outputId": "bedf7bba-9bc8-4b46-9bd3-58a074f56885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all texts and align the labels with them.\n",
        "padding = \"max_length\"\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[text_column_name],\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[label_column_name]):\n",
        "        # print('=====')\n",
        "        # print('{} {}'.format(i,label)) #ak\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "itvMJcvJ6B3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = small_train_dataset\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=4,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "gKaeyL8b5x8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = raw_datasets[\"validation\"]\n",
        "eval_dataset = eval_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=4,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on Validation dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "Jb0LU10t6EYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "FYytUt6U6GVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Unpack nested dictionaries\n",
        "    final_results = {}\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            for n, v in value.items():\n",
        "                final_results[f\"{key}_{n}\"] = v\n",
        "        else:\n",
        "            final_results[key] = value\n",
        "    return final_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtxyE9sn6Ip6",
        "outputId": "9bb43842-38de-40fd-c7c2-26608551c612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-435f98c90f62>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45jkKd3w6KW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our Trainer\n",
        "# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
        "# args.metric_for_best_model = \"f1\"\n",
        "# args.load_best_model_at_end = True\n",
        "# args.evaluation_strategy = IntervalStrategy.STEPS\n",
        "# args.eval_steps = args.save_steps\n",
        "# args.greater_is_better = True\n",
        "# Define training arguments\n",
        "num_epochs=3\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=num_epochs,  # Set the number of epochs\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=100,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    disable_tqdm=False,\n",
        "    load_best_model_at_end=True,  # Set load_best_model_at_end to True\n",
        "    learning_rate=0.0001,  # Set the learning rate here\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zez0qe956MLk",
        "outputId": "c1b99d2d-a20f-42ee-c477-59baa987e2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYKPtfZW6Ovj",
        "outputId": "1c085598-7d9e-4bd3-d859-365e9a63c253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "dispatch_batches=None,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_steps=100,\n",
              "evaluation_strategy=steps,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=False,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=0.0001,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=True,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./logs,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=10,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=linear,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=loss,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=adamw_torch,\n",
              "optim_args=None,\n",
              "output_dir=./results,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=16,\n",
              "per_device_train_batch_size=16,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard'],\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./results,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=500,\n",
              "save_strategy=steps,\n",
              "save_total_limit=2,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "split_batches=None,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.0,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "D06wfG6k8qoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "metrics = train_result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "95TT0qSp6QnB",
        "outputId": "7fa80a29-55a7-4ad7-c5cb-439a600c5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/3750 15:50 < 23:47, 1.58 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc Precision</th>\n",
              "      <th>Loc Recall</th>\n",
              "      <th>Loc F1</th>\n",
              "      <th>Loc Number</th>\n",
              "      <th>Org Precision</th>\n",
              "      <th>Org Recall</th>\n",
              "      <th>Org F1</th>\n",
              "      <th>Org Number</th>\n",
              "      <th>Per Precision</th>\n",
              "      <th>Per Recall</th>\n",
              "      <th>Per F1</th>\n",
              "      <th>Per Number</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.177500</td>\n",
              "      <td>0.293546</td>\n",
              "      <td>0.744015</td>\n",
              "      <td>0.773946</td>\n",
              "      <td>0.758685</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.636767</td>\n",
              "      <td>0.691418</td>\n",
              "      <td>0.662968</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.753128</td>\n",
              "      <td>0.780938</td>\n",
              "      <td>0.766781</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.720280</td>\n",
              "      <td>0.756426</td>\n",
              "      <td>0.737910</td>\n",
              "      <td>0.916994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.213200</td>\n",
              "      <td>0.283611</td>\n",
              "      <td>0.791841</td>\n",
              "      <td>0.725096</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.631068</td>\n",
              "      <td>0.689489</td>\n",
              "      <td>0.658986</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.767595</td>\n",
              "      <td>0.756487</td>\n",
              "      <td>0.762001</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.735236</td>\n",
              "      <td>0.731457</td>\n",
              "      <td>0.733342</td>\n",
              "      <td>0.916093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.164300</td>\n",
              "      <td>0.300783</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.651643</td>\n",
              "      <td>0.669238</td>\n",
              "      <td>0.660324</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.728782</td>\n",
              "      <td>0.788423</td>\n",
              "      <td>0.757430</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.716156</td>\n",
              "      <td>0.749816</td>\n",
              "      <td>0.732600</td>\n",
              "      <td>0.917391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.280933</td>\n",
              "      <td>0.729401</td>\n",
              "      <td>0.746169</td>\n",
              "      <td>0.737689</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.586460</td>\n",
              "      <td>0.693346</td>\n",
              "      <td>0.635440</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.765734</td>\n",
              "      <td>0.764970</td>\n",
              "      <td>0.765352</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.705540</td>\n",
              "      <td>0.741983</td>\n",
              "      <td>0.723303</td>\n",
              "      <td>0.915697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.252700</td>\n",
              "      <td>0.292777</td>\n",
              "      <td>0.691189</td>\n",
              "      <td>0.773946</td>\n",
              "      <td>0.730230</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.692938</td>\n",
              "      <td>0.652845</td>\n",
              "      <td>0.672294</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.756505</td>\n",
              "      <td>0.768962</td>\n",
              "      <td>0.762683</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.740759</td>\n",
              "      <td>0.731979</td>\n",
              "      <td>0.915552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.256301</td>\n",
              "      <td>0.735401</td>\n",
              "      <td>0.772031</td>\n",
              "      <td>0.753271</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.688325</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.670623</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.741981</td>\n",
              "      <td>0.784930</td>\n",
              "      <td>0.762852</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.727684</td>\n",
              "      <td>0.748348</td>\n",
              "      <td>0.737871</td>\n",
              "      <td>0.918219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.262400</td>\n",
              "      <td>0.261924</td>\n",
              "      <td>0.746896</td>\n",
              "      <td>0.749042</td>\n",
              "      <td>0.747967</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.640294</td>\n",
              "      <td>0.671167</td>\n",
              "      <td>0.655367</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.770367</td>\n",
              "      <td>0.754990</td>\n",
              "      <td>0.762601</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.729868</td>\n",
              "      <td>0.732191</td>\n",
              "      <td>0.731028</td>\n",
              "      <td>0.916814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.166500</td>\n",
              "      <td>0.271189</td>\n",
              "      <td>0.742723</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.750119</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.673611</td>\n",
              "      <td>0.654773</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.756895</td>\n",
              "      <td>0.739521</td>\n",
              "      <td>0.748107</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.732324</td>\n",
              "      <td>0.722644</td>\n",
              "      <td>0.727452</td>\n",
              "      <td>0.916309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.256300</td>\n",
              "      <td>0.745024</td>\n",
              "      <td>0.752874</td>\n",
              "      <td>0.748928</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.686408</td>\n",
              "      <td>0.681774</td>\n",
              "      <td>0.684083</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.739456</td>\n",
              "      <td>0.787425</td>\n",
              "      <td>0.762687</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.727898</td>\n",
              "      <td>0.751775</td>\n",
              "      <td>0.739644</td>\n",
              "      <td>0.919193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.291300</td>\n",
              "      <td>0.258744</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>0.717433</td>\n",
              "      <td>0.745274</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.627772</td>\n",
              "      <td>0.672521</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.755898</td>\n",
              "      <td>0.783433</td>\n",
              "      <td>0.769419</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.727050</td>\n",
              "      <td>0.740002</td>\n",
              "      <td>0.918616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.268100</td>\n",
              "      <td>0.247871</td>\n",
              "      <td>0.731115</td>\n",
              "      <td>0.778736</td>\n",
              "      <td>0.754174</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.653631</td>\n",
              "      <td>0.676953</td>\n",
              "      <td>0.665088</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.745014</td>\n",
              "      <td>0.782934</td>\n",
              "      <td>0.763504</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.718546</td>\n",
              "      <td>0.754957</td>\n",
              "      <td>0.736302</td>\n",
              "      <td>0.918075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.237300</td>\n",
              "      <td>0.255267</td>\n",
              "      <td>0.754402</td>\n",
              "      <td>0.779693</td>\n",
              "      <td>0.766839</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.662628</td>\n",
              "      <td>0.685632</td>\n",
              "      <td>0.673934</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.730751</td>\n",
              "      <td>0.790918</td>\n",
              "      <td>0.759645</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.719741</td>\n",
              "      <td>0.761322</td>\n",
              "      <td>0.739948</td>\n",
              "      <td>0.917715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.273091</td>\n",
              "      <td>0.748837</td>\n",
              "      <td>0.771073</td>\n",
              "      <td>0.759792</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.667308</td>\n",
              "      <td>0.669238</td>\n",
              "      <td>0.668272</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.757122</td>\n",
              "      <td>0.782435</td>\n",
              "      <td>0.769571</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.732680</td>\n",
              "      <td>0.750796</td>\n",
              "      <td>0.741627</td>\n",
              "      <td>0.917174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.213000</td>\n",
              "      <td>0.272804</td>\n",
              "      <td>0.732636</td>\n",
              "      <td>0.737548</td>\n",
              "      <td>0.735084</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.628947</td>\n",
              "      <td>0.691418</td>\n",
              "      <td>0.658705</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.742481</td>\n",
              "      <td>0.788423</td>\n",
              "      <td>0.764763</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.710118</td>\n",
              "      <td>0.750796</td>\n",
              "      <td>0.729891</td>\n",
              "      <td>0.915877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>0.712785</td>\n",
              "      <td>0.779693</td>\n",
              "      <td>0.744739</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.625967</td>\n",
              "      <td>0.702025</td>\n",
              "      <td>0.661818</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.742518</td>\n",
              "      <td>0.779940</td>\n",
              "      <td>0.760769</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.704082</td>\n",
              "      <td>0.760098</td>\n",
              "      <td>0.731018</td>\n",
              "      <td>0.916850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='391' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 02:34]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eVoFup_w6UPa",
        "outputId": "578d8613-5d59-4e06-ca29-5122e164f6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='169' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.7453\n",
            "  eval_LOC_number         =       1044\n",
            "  eval_LOC_precision      =     0.7754\n",
            "  eval_LOC_recall         =     0.7174\n",
            "  eval_ORG_f1             =     0.6725\n",
            "  eval_ORG_number         =       1037\n",
            "  eval_ORG_precision      =     0.7241\n",
            "  eval_ORG_recall         =     0.6278\n",
            "  eval_PER_f1             =     0.7694\n",
            "  eval_PER_number         =       2004\n",
            "  eval_PER_precision      =     0.7559\n",
            "  eval_PER_recall         =     0.7834\n",
            "  eval_loss               =     0.2587\n",
            "  eval_overall_accuracy   =     0.9186\n",
            "  eval_overall_f1         =       0.74\n",
            "  eval_overall_precision  =     0.7534\n",
            "  eval_overall_recall     =     0.7271\n",
            "  eval_runtime            = 0:00:23.97\n",
            "  eval_samples_per_second =    112.628\n",
            "  eval_steps_per_second   =       7.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = raw_datasets['test']\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "9dE89YyS6Upl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test_dataset)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D9hNX80H-r7J",
        "outputId": "3343e166-c1ba-4790-806c-e22161a0bb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.7886\n",
            "  eval_LOC_number         =        483\n",
            "  eval_LOC_precision      =     0.8372\n",
            "  eval_LOC_recall         =     0.7453\n",
            "  eval_ORG_f1             =      0.668\n",
            "  eval_ORG_number         =        263\n",
            "  eval_ORG_precision      =        0.7\n",
            "  eval_ORG_recall         =     0.6388\n",
            "  eval_PER_f1             =     0.8297\n",
            "  eval_PER_number         =        609\n",
            "  eval_PER_precision      =     0.8438\n",
            "  eval_PER_recall         =     0.8161\n",
            "  eval_loss               =      0.205\n",
            "  eval_overall_accuracy   =     0.9364\n",
            "  eval_overall_f1         =     0.7842\n",
            "  eval_overall_precision  =     0.8141\n",
            "  eval_overall_recall     =     0.7565\n",
            "  eval_runtime            = 0:00:07.50\n",
            "  eval_samples_per_second =    112.915\n",
            "  eval_steps_per_second   =      7.066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, ClassLabel, Value, Sequence\n",
        "\n",
        "# Assuming your data is structured like this:\n",
        "data = [\n",
        "{   \"tokens\": [     \"à°…à°¯à°¿à°¤à±‡\",     \"à°ˆ\",     \"à°¸à°¾à°°à°¿\",     \"à°…à°¨à±‚à°¹à±à°¯à°‚à°—à°¾\",     \"à°•à±‹à°Ÿà°¿\",     \"à°¯à°¾à°­à±ˆ\",     \"à°²à°•à±à°·à°²\",     \"à°ªà°²à°•à°¡à°‚à°¤à±‹\",     \"à°†\",     \"à°¡à°¬à±à°¬à±à°¨à±\",     \"à°à°‚\",     \"à°šà±‡à°¯à°¾à°²à±‹\",     \"à°‡à°‚à°•à°¾\",     \"à°¨à°¿à°°à±à°£à°¯à°¿à°‚à°šà±à°•à±‹à°²à±‡à°¦à°¨à°¿\",     \"à°—à±‹à°¯à°Ÿà±\",     \"à°šà±†à°ªà±à°ªà±à°•à±Šà°šà±à°šà°¾à°¡à±\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "{   \"tokens\": [     \"à°ªà±à°°à°œà°²\",     \"à°®à°¨à±‹à°­à°¾à°µà°¾à°²à±,\",     \"à°Žà°®à±‹à°·à°¨à±à°¸à±\",     \"à°•à°¿\",     \"à°…à°‚à°¤à°—à°¾\",     \"à°ªà±à°°à°¾à°®à±à°–à±à°¯à°¤\",     \"à°‡à°µà±à°µà°•à±à°‚à°¡à°¾\",     \"à°¤à°¾à°¨à±à°…à°¨à±à°•à±à°¨à±à°¨\",     \"à°ªà°¨à±à°²à±\",     \"à°šà°•à±à°•à°¬à±†à°Ÿà±à°Ÿà±‡à°µà°¾à°°à±\",   \" .\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",  \"O\"   ] },\n",
        "{   \"tokens\": [     \"à°…à°ªà±à°ªà±à°¡à±,\",     \"à°®à±€à°°à±\",     \"à°šà°¿à°µà°°à°•à±\",     \"à°šà±‚à°¸à±à°¤à±à°¨à±à°¨\",     \"à°ªà±†à°°à±à°—à±à°¦à°²\",     \"à°…à°²à°µà°¾à°Ÿà±\",     \"à°°à°•à°‚\",     \"à°ªà±à°°à±‹à°¤à±à°¸à°¹à°¿à°‚à°šà°¡à°¾à°¨à°¿à°•à°¿\",     \"à°¨à±à°¯à°¾à°¯à°®à±ˆà°¨\",     \"à°•à°Ÿà±à°¸à±\",     \"à°¤à°¯à°¾à°°à±\",  \".\"  ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\", \"O\"   ] },\n",
        "{   \"tokens\": [ \"à°Žà°¨à±à°¨à°¿à°•à°²\", \"à°ªà±à°°à°•à°Ÿà°¨\", \"à°µà±†à°²à±à°µà°¡à°¿à°¨à°¦à°¿\", \"à°²à°—à°¾à°¯à°¤à±\", \"à°¸à±€à°Ÿà±à°²\", \"à°ªà°‚à°ªà°•à°‚\", \"à°•à±‹à°¸à°‚\", \"à°•à±Šà°Ÿà±à°Ÿà±à°•à±‹à°µà°¡à°®à±‡\", \"à°®à°¹à°¾à°•à±‚à°Ÿà°®à°¿à°•à°¿\", \"à°¸à°°à°¿à°ªà±‹à°¤à±à°¨à±à°¨à°¦à°¿\", \"à°ªà±à°°à°¤à°¿à°°à±‹à°œà±‚\", \"à°‰à°¦à°¯à°‚\", \"à°‡à°‚à°Ÿà±à°²à±‹\", \"à°Ÿà°¿à°«à°¿à°¨à±\", \"à°šà±†à°¯à±à°¯à°¡à°‚\", \"à°—à±‹à°²à±à°•à±Šà°‚à°¡\", \"à°°à°¿à°¸à°¾à°°à°Ÿà±à°¸à±à°•à±\", \"à°µà±†à°³à±à°²à°¿\", \"à°ªà°¿à°šà±à°šà°¾à°ªà°¾à°Ÿà±€\", \"à°®à°¾à°Ÿà±à°²à°¾à°¡à±à°•à±à°¨à°¿\", \"à°­à±‹à°œà°¨à°‚\", \"à°šà±†à°¯à±à°¯à°¡à°‚\", \"à°‡à°‚à°Ÿà°¿à°•à°¿\", \"à°µà±†à°³à±à°²à°¡à°‚\", \"à°®à°°à±à°¨à°¾à°¡à±\", \"à°®à°³à±à°³à±€\", \"à°…à°¦à±‡\", \"à°¤à°‚à°¤à±\", \"à°•à°¾à°‚à°—à±à°°à±†à°¸à±\", \"à°ªà°¾à°°à±à°Ÿà±€à°•à°¿\", \"à°•à°¾à°°à±à°¯à°•à°°à±à°¤à°²à±\", \"à°¤à°•à±à°•à±à°µ\", \"à°¨à°¾à°¯à°•à±à°²à±\", \"à°Žà°•à±à°•à±à°µ\", \"à°¸à°°à±à°ªà°‚à°šà±\", \"à°—à°¾\", \"à°•à±‚à°¡à°¾\", \"à°šà±‡à°¯à°¨à°¿à°µà°¾à°¡à±\", \"à°®à±à°–à±à°¯à°®à°‚à°¤à±à°°à°¿\", \"à°•à°¾à°µà°¾à°²à°¨à±à°•à±à°‚à°Ÿà°¾à°°à±\", \"à°†\", \"à°ªà°¾à°°à±à°Ÿà±€à°²à±‹\", \"à°…à°‚à°¦à±à°•à±‡\", \"à°Žà°ªà±à°ªà±à°¡à±\", \"à°Žà°¨à±à°¨à°¿à°•à°²à±\", \"à°µà°šà±à°šà°¿à°¨à°¾\", \"à°•à°¾à°‚à°—à±à°°à±†à°¸à±\", \"à°ªà°¾à°°à±à°Ÿà±€à°²à±‹\", \"à°…à°‚à°¤à°°à±à°—à°¤\", \"à°¯à±à°¦à±à°§à°‚\", \"à°®à±Šà°¦à°²à°µà±à°¤à±à°‚à°¦à°¿\", \"à°µà°¾à°°à°¿à°•à°¿\", \"à°µà°¾à°°à±‡\", \"à°µà±†à°¨à±à°¨à±à°ªà±‹à°Ÿà±à°²à±\", \"à°ªà±Šà°¡à±à°šà±à°•à±à°‚à°Ÿà°¾à°°à±\", \"à°¤à°®à°•à±\", \"à°®à±à°ªà±à°«à°¯à°¿\", \"à°¸à±€à°Ÿà±à°²à±\", \"à°•à°¾à°µà°¾à°²à°¨à°¿\", \"à°Ÿà±€à°œà±‡à°Žà°¸à±\", \"à°¤à°®à°•à±\", \"à°¨à°²à°­à±ˆ\", \"à°•à°¾à°µà°¾à°²à°¨à°¿\", \"à°¤à±†à°²à±à°—à±à°¦à±‡à°¶à°‚\", \"à°•à°¾à°‚à°—à±à°°à±†à°¸à±\", \"à°ªà°¾à°°à±à°Ÿà±€à°•à°¿\", \"à°¹à±†à°šà±à°šà°°à°¿à°•à°²à±\", \"à°œà°¾à°°à±€\", \"à°šà±‡à°¸à±à°¤à±à°¨à±à°¨à°¾à°¯à°¿\", \"à°²à±‡à°•à°ªà±‹à°¤à±†\", \"à°¤à°®\", \"à°¦à°¾à°°à°¿\", \"à°¤à°¾à°®à±\", \"à°šà±‚à°¸à±à°•à±à°‚à°Ÿà°¾à°®à°¨à°¿\", \"à°¬à±†à°¦à°¿à°°à°¿à°‚à°ªà±à°²à°•à±\", \"à°¦à°¿à°—à±à°¤à±à°¨à±à°¨à°¾à°¯à°¿\", \"à°†\", \"à°°à±†à°‚à°¡à±\", \"à°ªà°¾à°°à±à°Ÿà±€à°²à°•à±‡\", \"à°…à°°à°µà±ˆ\", \"à°¡à±à°¬à±à°¬à±ˆ\", \"à°¸à±à°¥à°¾à°¨à°¾à°²à±\", \"à°‡à°šà±à°šà°¿\", \"à°‡à°•\", \"à°•à°¾à°‚à°—à±à°°à±†à°¸à±\", \"à°ªà±‹à°Ÿà±€\", \"à°šà±‡à°¸à±‡à°¦à°¿\", \"à°Žà°¨à±à°¨à°¿\", \"à°¸à±à°¥à°¾à°¨à°¾à°²à°²à±‹\", \"à°¨à°µà±à°µà±\", \"à°°à°¾à°µà°¡à°‚\", \"à°²à±‡à°¦à±‚\", \"à°Žà°¨à±à°¨à°¿à°•à°²à±\", \"à°…à°¯à±à°¯à±‡à°‚à°¤à°µà°°à°•à±‚\", \"à°ªà°°à°¸à±à°ªà°°à°‚\", \"à°•à°²à°¹à°¿à°‚à°šà±à°•à±‹à°µà°¡à°‚à°²à±‹à°¨à±‡\", \"à°•à°¾à°²à°•à±à°·à±‡à°ªà°‚\", \"à°®à°¹à°¾à°•à±‚à°Ÿà°®à°¿\", \"à°Žà°¨à±à°¨à°¿à°•à°²à±à°²à±‹\", \"à°ªà±‹à°Ÿà±€\", \"à°šà±‡à°¸à°¿\", \"à°µà°¿à°œà°¯à°‚\", \"à°¸à°¾à°§à°¿à°‚à°šà°¡à°‚\", \"à°…à°¯à±à°¯à±‡à°ªà°¨à±‡à°¨à°¾\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"B-ORG\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"à°®à±†à°—à°¾\", \"à°ªà°µà°°à±\", \"à°¸à±à°Ÿà°¾à°°à±\", \"à°°à°¾à°®à±\", \"à°šà°°à°£à±\", \",\", \"à°Šà°°à°®à°¾à°¸à±\", \"à°¡à±ˆà°°à±†à°•à±à°Ÿà°°à±\", \"à°¬à±‹à°¯à°ªà°¾à°Ÿà°¿\", \"à°¶à±à°°à±€à°¨à±\", \"à°•à°¾à°‚à°¬à°¿à°¨à±‡à°·à°¨à±â€Œà°²à±‹\", \",\", \"à°«à±à°¯à°¾à°®à°¿à°²à±€\", \",\", \"à°²à°µà±\", \"à°…à°‚à°¡à±\", \"à°¯à°¾à°•à±à°·à°¨à±\", \"à°Žà°‚à°Ÿà°°à±â€Œà°Ÿà±ˆà°¨à°°à±â€Œà°—à°¾\", \"à°°à±‚à°ªà±Šà°‚à°¦à°¿à°¨\", \"à°µà°¿à°¨à°¯\", \"à°µà°¿à°§à±‡à°¯\", \"à°°à°¾à°®à±\", \",\", \"à°œà°¨à°µà°°à°¿\", \"11à°¨\", \"à°µà°°à°²à±à°¡à±\", \"à°µà±ˆà°¡à±\", \"à°—à±à°°à°¾à°‚à°¡à±\", \"à°°à°¿à°²à±€à°œà±â€Œà°•à°¿\", \"à°°à±†à°¢à±€\", \"à°…à°¯à°¿à°ªà±‹à°¯à°¿à°‚à°¦à°¿\", \".\", \"à°¡à°¿.à°µà°¿.à°µà°¿.\", \"à°¦à°¾à°¨à°¯à±à°¯\", \"à°¨à°¿à°°à±à°®à°¿à°‚à°šà°—à°¾\", \",\", \"à°•à±ˆà°°à°¾\", \"à°…à°¦à±à°µà°¾à°£à±€\", \"à°¹à±€à°°à±‹à°¯à°¿à°¨à±â€Œà°—à°¾\", \"à°¨à°Ÿà°¿à°‚à°šà°¿à°‚à°¦à°¿\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"à°…à°¦à°¿,\", \"à°ªà±Šà°‚à°¦à±à°Ÿà°•à±\", \",\",  \"à°®à±‡à°®à±\", \"à°ªà±à°°à°§à°¾à°¨\", \"à°¦à±à°µà°¾à°°à°‚\", \"à°¨à±à°‚à°¡à°¿\", \"à°•à±à°¡à°¿\", \"à°šà±†à°¯à±à°¯à°¿\", \"à°®à°°à°¿à°¯à±\", \"à°¨à°¿à°°à°‚à°¤à°°à°‚\", \"à°ªà±†à°°à±à°—à±à°¤à±à°‚à°¦à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "  { \"tokens\": [ \"à°²à±‹à°¤à±†à±–à°¨\", \"à°¸à°®à°¾à°µà±‡à°¶à°‚à°²à±‹\", \",\", \"à°¸à°¾à°°à°¾à°‚à°¶à°‚\", \"à°®à°¾à°¨à°µ\", \"à°¶à°°à±€à°°à°‚à°²à±‹\", \"à°¨à±à°‚à°¡à°¿\", \"à°µà±‡à°°à±\", \",\", \"à°…à°¸à±à°¤à°¿à°¤à±à°µ\", \"à°®à°°à°£à°‚\", \"à°…à°¨à°¿\", \"à°ªà°¿à°²à±à°µà°¬à°¡à±à°¤à±à°‚à°¦à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"à°šà°¾à°Ÿà±à°¸à°¾à°¹à°¿à°¤à±à°¯à°‚à°²à±‹\", \"à°¤à°°à°šà±‚\", \"à°•à°¨à°¿à°ªà°¿à°‚à°šà±‡\", \"à°²à°•à±à°·à°£à°‚\", \"â€“\", \"à°ªà°¦à±à°¯à°¾à°²\", \"à°—à±à°°à°¿à°‚à°šà±€\", \",\", \"à°•à°µà±à°²\", \"à°—à±à°°à°¿à°‚à°šà±€\", \"à°œà°¨à°µà±à°¯à°µà°¹à°¾à°°à°‚à°²à±‹\", \"à°µà±à°¯à°¾à°ªà±à°¤à°®à±ˆà°¯à±à°¯à±‡\", \"à°•à°¥à°²à±\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\",  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"à°¬à±à°°à±‡à°•à°¿à°‚à°—à±\", \":\", \"à°®à°³à±à°³à±€\", \"à°µà±ˆà°¸à±€à°ªà±€à°²à±‹à°•à°¿\", \"à°Žà°‚à°Ÿà±à°°à±€\", \"à°‡à°¸à±à°¤à±à°¨à±à°¨\", \"à°•à±€à°²à°•\", \"à°¨à±‡à°¤\", \"..\", \"à°·à°¾à°•à±â€Œà°²à±‹\", \"à°Ÿà±€à°¡à±€à°ªà±€\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\"] },\n",
        " { \"tokens\": [ \"à°ªà±à°°à°¾à°®à°¾à°£à°¿à°•\", \"à°¬à±à°¯à°¾à°‚à°•à±\", \"à°°à±à°£\", \"à°œà°¾à°°à±€\", \"à°•à°¾à°•à±à°‚à°¡à°¾\", \",\", \"à°•à±à°°à±†à°¡à°¿à°Ÿà±\", \"à°¯à±Šà°•à±à°•\", \"à°²à±†à±–à°¨à±\", \"à°†à°°à±à°¥à°¿à°•\", \"à°¸à°‚à°¸à±à°¥à°²\", \"à°°à±à°£à°—à±à°°à°¹à±€à°¤à°²à±\", \"à°®à°°à°¿à°‚à°¤\", \"à°†à°•à°°à±à°·à°£à±€à°¯à°‚à°—à°¾\", \",\", \"à°…à°²à°¾à°—à±‡\", \"à°‰à°‚à°¦à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"à°µà°¾à°°à°¿\", \"à°ªà±à°°à°•à°¾à°¶à°µà°‚à°¤à°®à±†à±–à°¨\", \"à°¨à°•à±à°·à°¤à±à°°à°¾à°²à±\", \"à°¸à°¿à°°à°¿à°¯à°¸à±\", \"à°®à°°à°¿à°¯à±\", \"Procyon\", \"à°\", \"à°‡à°¤à°°\", \"à°¤à±‹\", \"à°¤à°¿à°•à°®à°•\", \"à°•à°·à±à°Ÿà°‚\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"à°ªà±€à°Ÿà°°à±à°¸à±à°¬à°°à±à°—à±\", \"à°ªà°¤à°¨à°‚\", \"à°¤à°°à±à°µà°¾à°¤\", \"à°²à±€\", \"à°¯à±Šà°•à±à°•\", \"à°µà±†à°¨à±à°•à°µà±ˆà°ªà±\", \"à°‰à°¨à±à°¨\", \"à°¸à±ˆà°¨à°¿à°•à°¦à°³à°¾à°¨à±à°¨à°¿\", \"à°•à±Šà°¨à°¸à°¾à°—à°¿à°‚à°šà°¡à°‚à°¤à±‹\", \",\",  \"à°°à±ˆà°Ÿà±\", \"à°®à°°à°¿à°¯à±\", \"VI\", \"à°•à°¾à°°à±à°ªà±à°¸à±\", \"à°®à°³à±à°²à±€\", \"à°·à±†à°°à°¿à°¡à°¾à°¨à±\", \"à°¦à°¿à°¶à°—à°¾\", \"à°µà°šà±à°šà°¾à°°à±\", \".\" ], \"ner_tags\": [ \"B-PER\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"B-PER\",  \"O\", \"B-LOC\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"à°¦à°¾à°¨à°¿à°ªà±†à±–\", \"à°¹à±†à±–à°¡à±\", \"à°ªà±à°°à°¦à°°à±à°¶à°¨\", \"à°²à°•à±à°·à°£à°¾à°²à±\", \"à°’à°•\", \"à°ªà±à°°à°¾à°¥à°®à°¿à°•\", \"à°µà°¿à°µà°°à°£\", \"à°¤à±‹\", \"à°ªà±à°°à°¾à°°à°‚à°­à°‚\", \"à°•à°¾à°µà°¾à°²à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"à°®à±‹à°°à±†à°¨à°¾\", \"à°œà°¿à°²à±à°²à°¾\", \"à°œà±Œà°°à°¾\", \"à°ªà±à°°à°¾à°‚à°¤à°‚à°²à±‹\", \"à°œà°°à°¿à°—à°¿à°¨\", \"à°’à°•\", \"à°Žà°¨à±à°¨à°¿à°•à°²\", \"à°¸à°­à°²à±‹\", \"à°°à°¾à°¹à±à°²à±\", \"à°®à°¾à°Ÿà±à°²à°¾à°¡à±à°¤à±‚\", \"à°Žà°‚à°œà±‡\", \"à°…à°•à±à°¬à°°à±â€Œà°ªà±ˆ\", \"à°ªà°²à±à°µà±à°°à±\", \"à°®à°¹à°¿à°³à°¾\", \"à°œà°°à±à°¨à°²à°¿à°¸à±à°Ÿà±à°²à±\", \"à°šà±‡à°¸à°¿à°¨\", \"à°²à±ˆà°‚à°—à°¿à°•\", \"à°¦à°¾à°¡à°¿\", \"à°†à°°à±‹à°ªà°£à°²à°¨à±\", \"à°¦à±ƒà°·à±à°Ÿà°¿à°²à±‹\", \"à°ªà±†à°Ÿà±à°Ÿà±à°•à±Šà°¨à°¿\", \"à°®à±‹à°¦à±€\", \"à°ªà±à°°à°­à±à°¤à±à°µà°¾à°¨à±à°¨à°¿\", \"à°¨à°¿à°²à°¦à±€à°¶à°¾à°°à±\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\" ] },\n",
        "\n",
        " #  { \"tokems\": [ \"à°•à°¾à°¨à±à°¸à±à°Ÿà°¾à°‚à°Ÿà°¿à°¨à±‹à°ªà±à°²à±à°²à±‹\", \"à°¬à±‹à°¹à±†à°‚à°‚à°¡à±\", \"à°®à±à°–à±à°¯à°‚à°—à°¾\", \"à°¸à±à°µà°¾à°—à°¤à°‚\", \"à°²à±‡à°¦à±\", \"à°Žà°‚à°¦à±à°•à°‚à°Ÿà±‡\", \"à°…à°¤à°¨à°¿\", \"à°¤à°‚à°¡à±à°°à°¿\", \",\", \"à°°à°¾à°¬à°°à±à°Ÿà±\", \"à°—à±ˆà°•à°¾à°°à±à°¡à±\", \",\", \"à°¬à±ˆà°œà°¾à°‚à°Ÿà±ˆà°¨à±\", \"à°¸à°¾à°®à±à°°à°¾à°œà±à°¯à°¾à°¨à±à°¨à°¿\", \"à°†à°•à±à°°à°®à°¿à°‚à°šà°¿\", \",\", \"à°¡à°¿à°¯à°°à±à°¹à°šà±à°¯à±‚à°®à±\", \"à°®à°°à°¿à°¯à±\", \"à°•à±‹à°°à±à°«à±\", \"à°¨à°—à°°à°¾à°²à°¨à±\", \"à°¸à±à°µà°¾à°§à±€à°¨à°‚\", \"à°šà±‡à°¸à±à°•à±à°¨à±à°¨à°¾à°¡à±\", \".\" ], \"ner_tags\": [ 6, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 6, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0 ] },\n",
        " #   { \"tokems\": [ \"à°¶à°¿à°–à°°à°‚\", \"(\", \"à°‰à°¤à±à°¤à°®\", \"à°¸à°®à°¯à°‚\", \"-\", \"à°¸à°¾à°¯à°‚à°¤à±à°°à°‚\", \"à°®à±à°–à±à°¯à°‚à°—à°¾\", \"â€œ\", \"à°µà°°à±à°·à°‚\", \"à°•à°¿à°‚à°¦\", \"â€œ\", \")\", \"à°¯à±Šà°•à±à°•\", \"à°µà±‡à°¡à°¿\", \"à°®à°¾à°¨à±à°•à±‹à°‚à°¡à°¿\", \";\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #  { \"tokems\": [ \"à°à°¦à±ˆà°¨à°¾\", \"à°’à°•\", \"à°¨à±€à°Ÿà°¿\", \"à°ªà°¾à°°à±à°¦à°²\", \"à°ªà±à°°à°¾à°œà±†à°•à±à°Ÿà±à°•à±\", \"à°œà°¾à°¤à±€à°¯\", \"à°¹à±‹à°¦à°¾à°¨à±\", \"à°‡à°µà±à°µà°¾à°²à°¨à°¿\", \"à°•à±‹à°°à±‡\", \"à°…à°µà°•à°¾à°¶à°‚\", \"à°‰à°‚à°¦à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #{ \"tokems\": [ \"à°ªà±à°°à±ˆà°µà±‡à°Ÿà±à°¸à±â€Œ\", \"à°ªà±‹à°²à±à°¸à±â€Œà°¨à±\", \"à°¬à°Ÿà±à°Ÿà°¿\", \"à°šà±‚à°¸à±à°¤à±‡\", \"à°µà°¿à°¤à°¿à°•\", \"à°ªà°°à°¿à°¸à±à°¥à°¿à°¤à°¿\", \"à°®à°¾à°¤à±à°°à°‚\", \"à°¦à°¾à°°à±à°£à°‚à°—à°¾\", \"à°‰à°¨à±à°¨à°Ÿà±à°²à±\", \"à°¤à±†à°²à±à°¸à±à°¤à±‹à°‚à°¦à°¿\", \".\" ], \"ner_tags\": [ 0,0,0,0,0,0,0,0,0,0,0 ] },\n",
        " # { \"tokems\": [ \"à°¬à°‚à°—à±à°²à°¾\", \"à°“à°ªà±†à°¨à°°à±\", \"à°·à°¾à°¦à±â€Œà°®à°¨à±â€Œ\", \"à°‡à°¸à±à°²à°¾à°®à±â€Œ.\", \"(\", \"29\", \")\", \"à°«à°°à±à°µà°¾à°²à±‡à°¦à°¨à°¿à°ªà°¿à°‚à°šà°—à°¾\", \"...\", \"à°®à°°à±‹\", \"à°“à°ªà±†à°¨à°°à±\", \"à°‡à°®à±à°°à±à°²à±â€Œ\", \"(\", \"4\", \")\", \"à°¨à°¿à°°à°¾à°¶à°ªà°°à°¿à°šà°¾à°¡à±\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # { \"tokems\": [ \"à°…à°¯à°¿à°¤à±‡\", \"à°µà°¾à°Ÿà°¿à°•à°¿\", \"à°¹à±ˆà°¨à±†à°•à±â€Œ\", \"à°¬à±à°²à°µà±à°œà±à°²à±\", \",\", \"à°•à°¾à°²à°°à±à°¸à±â€Œ\", \",\", \"à°«à±à°²à±â€Œà°¸à±à°²à±€à°µà±à°¸à±â€Œ\", \",\", \"à°•à±à°²à±‹à°œà±à°¡à±â€Œ\", \",\", \"à°¬à±‹à°Ÿà±â€Œ\", \",\", \"à°¬à±à°¯à°¾à°•à±â€Œà°¹à±ˆà°¨à±†à°•à±\", \"â€Œ,\", \"à°«à±à°°à°‚à°Ÿà±â€Œ\", \"à°°à±Œà°‚à°¡à±â€Œà°¨à±†à°•à±â€Œ\", \"à°¬à±à°²à°µà±à°œà±â€Œà°²à±\", \"à°¬à°¾à°—à±à°‚à°Ÿà°¾à°¯à°¿\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # {    \"tokems\": [     \"4\",     \")\",     \"à°ªà±ˆà°¨\",     \"à°šà±†à°ªà±à°ªà°¿à°¨\",     \"à°µà°¿\",     \"à°…à°¨à°—à°¾\",     \"à°•à°²à°¿à°ªà°¿\",     \"à°ªà±†à°Ÿà±à°Ÿà±à°•à±à°¨à±à°¨\",     \"à°°à°µà±à°µ\",     \",\",     \"à°‰à°¡à°¿à°•à°¿à°‚à°šà°¿à°¨\",     \"à°†à°²à±‚\",     \",\",     \"à°•à°Ÿà±\",     \"à°šà±†à°¸à°¿\",     \"à°ªà±†à°Ÿà±à°Ÿà°•à±à°¨à±à°¨à°µà°¿\",     \"à°…à°¨à±à°¨à°¿\",     \"à°‡à°‚à°•à°¾\",     \"à°œà°¿à°²à°•à°°à±à°°\",     \",\",     \"à°‰à°ªà±à°ªà±\",     \"à°°à±à°šà°¿\",     \"à°•à°¿\",     \"à°¸à°°à°¿à°ªà°¡\",     \".\",     \"à°µà±†à°¸à°¿\",     \"à°®à±à°¦à±à°¦\",     \"à°²à°¾\",     \"à°•à°²à±à°ªà±à°•à±‹à°µà°¾à°²à±€\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] },\n",
        " #{   \"tokems\": [     \"à°¸à°¿à°¨à°¿à°®à°¾à°²à±‹\",     \"à°•à°‚à°Ÿà±†à°‚à°Ÿà±\",     \"à°…à°‚à°¤à°‚à°¤à°®à°¾à°¤à±à°°à°®à±‡\",     \"à°…à°¯à°¿à°¨à°ªà±à°ªà°Ÿà°¿à°•à±€\",     \"..\",     \"à°ˆ\",     \"à°®à°¾à°¤à±à°°à°‚\",     \"à°µà°¸à±‚à°³à±à°²à±\",     \"à°µà°šà±à°šà°¾à°¯à°‚à°Ÿà±‡\",     \"à°…à°¦à°¿\",     \"à°Žà°¨à±à°Ÿà±€à°†à°°à±\",     \"à°ªà±†à°°à±à°«à°¾à°®à±†à°¨à±à°¸à±â€Œ\",     \"à°µà°²à±à°²à±‡\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "  #{   \"tokems\": [     \"â€˜\",     \"à°¸à±à°Ÿà°¾à°°à±à°¸à±\",     \"â€Œâ€™\",     \"(\",     \"à°¸à±à°•à±€à°®à±â€Œ\",     \"à°«à°°à±â€Œ\",     \"à°Ÿà±à°°à°¾à°¨à±à°¸à±â€Œà°«à°°à±à°®à±‡à°·à°¨à±â€Œ\",     \"à°…à°‚à°¡à±â€Œ\",     \"à°…à°¡à±à°µà°¾à°¨à±à°¸à±â€Œà°¡à±â€Œ\",     \"à°°à±€à°¸à±†à°°à±à°šà±â€Œ\",     \"à°‡à°¨à±â€Œ\",     \"à°¬à±‡à°¸à°¿à°•à±â€Œ\",     \"à°¸à±ˆà°¨à±à°¸à±†à°¸à±\",     \")\",     \",\",     \"à°à°à°Žà°¸à±â€Œà°¸à±€\",     \"à°¬à±†à°‚à°—à°³à±‚à°°à±\",     \"à°¦à±à°µà°¾à°°à°¾\",     \"à°…à°§à±à°¯à°¯à°¨\",     \"à°•à°¾à°°à±à°¯à°•à±à°°à°®à°¾à°²à°¨à±\",     \"à°®à°‚à°œà±‚à°°à±\",     \"à°šà±‡à°¸à±à°¤à±à°¨à±à°¨à°¾à°°à±\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"B-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"O\",     \"O\",     \"B-ORG\",     \"B-LOC\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] }\n",
        "    # More records...\n",
        "]\n",
        "\n",
        "# Transform your list of dictionaries into the expected format\n",
        "transformed_data = {\n",
        "    \"tokens\": [item[\"tokens\"] for item in data],\n",
        "    \"ner_tags\": [item[\"ner_tags\"] for item in data],\n",
        "}\n",
        "\n",
        "# Define the features of your dataset, aligning with your manual data structure\n",
        "features = Features({\n",
        "    'tokens': Sequence(feature=Value(dtype='string')),\n",
        "    'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']))\n",
        "})\n",
        "\n",
        "# Create a Dataset object from your transformed data\n",
        "question1_data = Dataset.from_dict(transformed_data, features=features)\n",
        "\n",
        "# Now you can access column_names and features just like your training dataset\n",
        "column_names = question1_data.column_names\n",
        "print(column_names)\n",
        "\n",
        "dataset_features = question1_data.features\n",
        "print(dataset_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0k09Md1_nJ6",
        "outputId": "f1ee906e-7621-492c-d503-764adecba996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'ner_tags']\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = question1_data\n",
        "test = test.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2232ff5a7d274706a74bbaf1b6bdbadc",
            "c4a35520eb1d4550808d1c20930d4e1b",
            "fe67a50711d449ff91362506fffd27f1",
            "c19bf97e8999485b9074115e122b28ed",
            "b2dfa01082744d19b72dc9d035755211",
            "652736cc03454854ad10c47657edbf1f",
            "eeafacca2a144d20864d36ddb20a0913",
            "4051e27c50544d6bb6b2416518aa5ac6",
            "87b84eb3406545b3a96b0835cc2800f3",
            "c118ba6bc38b45a3858d28a2eb20a515",
            "2e44032a27d144acb3bf98b5255b4d81"
          ]
        },
        "id": "O5R_Od5_DtZD",
        "outputId": "07c62e9d-45ae-47ad-97e9-40060034e32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on train dataset (num_proc=6):   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2232ff5a7d274706a74bbaf1b6bdbadc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9LDReNDsDwMc",
        "outputId": "7560117a-7c6a-4ec1-e719-3636bd224606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='223' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 07:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.3333\n",
            "  eval_LOC_number         =          5\n",
            "  eval_LOC_precision      =        1.0\n",
            "  eval_LOC_recall         =        0.2\n",
            "  eval_ORG_f1             =     0.4706\n",
            "  eval_ORG_number         =         11\n",
            "  eval_ORG_precision      =     0.6667\n",
            "  eval_ORG_recall         =     0.3636\n",
            "  eval_PER_f1             =     0.5385\n",
            "  eval_PER_number         =         14\n",
            "  eval_PER_precision      =     0.5833\n",
            "  eval_PER_recall         =        0.5\n",
            "  eval_loss               =      0.335\n",
            "  eval_overall_accuracy   =     0.9034\n",
            "  eval_overall_f1         =     0.4898\n",
            "  eval_overall_precision  =     0.6316\n",
            "  eval_overall_recall     =        0.4\n",
            "  eval_runtime            = 0:00:00.16\n",
            "  eval_samples_per_second =     83.646\n",
            "  eval_steps_per_second   =      5.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAa_9Z26FMA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}