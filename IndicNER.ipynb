{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2232ff5a7d274706a74bbaf1b6bdbadc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4a35520eb1d4550808d1c20930d4e1b",
              "IPY_MODEL_fe67a50711d449ff91362506fffd27f1",
              "IPY_MODEL_c19bf97e8999485b9074115e122b28ed"
            ],
            "layout": "IPY_MODEL_b2dfa01082744d19b72dc9d035755211"
          }
        },
        "c4a35520eb1d4550808d1c20930d4e1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_652736cc03454854ad10c47657edbf1f",
            "placeholder": "​",
            "style": "IPY_MODEL_eeafacca2a144d20864d36ddb20a0913",
            "value": "Running tokenizer on train dataset (num_proc=6): 100%"
          }
        },
        "fe67a50711d449ff91362506fffd27f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4051e27c50544d6bb6b2416518aa5ac6",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87b84eb3406545b3a96b0835cc2800f3",
            "value": 14
          }
        },
        "c19bf97e8999485b9074115e122b28ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c118ba6bc38b45a3858d28a2eb20a515",
            "placeholder": "​",
            "style": "IPY_MODEL_2e44032a27d144acb3bf98b5255b4d81",
            "value": " 14/14 [00:00&lt;00:00, 76.82 examples/s]"
          }
        },
        "b2dfa01082744d19b72dc9d035755211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "652736cc03454854ad10c47657edbf1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeafacca2a144d20864d36ddb20a0913": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4051e27c50544d6bb6b2416518aa5ac6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b84eb3406545b3a96b0835cc2800f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c118ba6bc38b45a3858d28a2eb20a515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e44032a27d144acb3bf98b5255b4d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAD5DKqk4rYG",
        "outputId": "d9737e54-7f4e-42f7-cff2-6dc534d2bd7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip3 install sentencepiece\n",
        "!pip3 install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all the necessary classes and initialize the tokenizer and model.\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "import torch\n",
        "from transformers import AutoModelForTokenClassification, AutoConfig, AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification, EarlyStoppingCallback, IntervalStrategy\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ai4bharat/IndicNER\")\n",
        "\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"ai4bharat/IndicNER\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJlT6sik4yLm",
        "outputId": "c5a5cd3d-bb5a-4f0b-8fd0-886602ab6d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions( sentence, tokenizer, model ):\n",
        "  # Let us first tokenize the sentence - split words into subwords\n",
        "  tok_sentence = tokenizer(sentence, return_tensors='pt')\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # we will send the tokenized sentence to the model to get predictions\n",
        "    logits = model(**tok_sentence).logits.argmax(-1)\n",
        "\n",
        "    # We will map the maximum predicted class id with the class label\n",
        "    predicted_tokens_classes = [model.config.id2label[t.item()] for t in logits[0]]\n",
        "\n",
        "    predicted_labels = []\n",
        "\n",
        "    previous_token_id = 0\n",
        "    # we need to assign the named entity label to the head word and not the following sub-words\n",
        "    word_ids = tok_sentence.word_ids()\n",
        "    for word_index in range(len(word_ids)):\n",
        "        if word_ids[word_index] == None:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        elif word_ids[word_index] == previous_token_id:\n",
        "            previous_token_id = word_ids[word_index]\n",
        "        else:\n",
        "            predicted_labels.append( predicted_tokens_classes[ word_index ] )\n",
        "            previous_token_id = word_ids[word_index]\n",
        "\n",
        "    return predicted_labels"
      ],
      "metadata": {
        "id": "yoiu2P1o40FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's download the Naampadam (Indic NER) dataset\n",
        "from datasets import ClassLabel, load_dataset, load_metric, DownloadMode\n",
        "\n",
        "lang='te'\n",
        "\n",
        "raw_datasets = load_dataset('ai4bharat/naamapadam', lang)"
      ],
      "metadata": {
        "id": "aW6w52sn42Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_dataset = raw_datasets[\"train\"].select(range(20000))\n",
        "\n",
        "# Print the length of the small dataset\n",
        "print(len(small_train_dataset))\n",
        "small_train_dataset.column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c8UIMn543j5",
        "outputId": "7606d1a4-6383-48f5-bbff-d3c33a1c2e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tokens', 'ner_tags']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's print an instance of dataset\n",
        "idx=10\n",
        "rec=small_train_dataset[idx]\n",
        "for w, t in zip(rec['tokens'],rec['ner_tags']):\n",
        "  print('{}\\t{}'.format(w,t))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUkCW8yw47HQ",
        "outputId": "f8ab5f1c-b557-4b86-b4ec-a68d3edb93f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ఈ\t0\n",
            "సినిమా\t0\n",
            "కూడా\t0\n",
            "మంచి\t0\n",
            "హిట్\t0\n",
            "అయినది\t0\n",
            ".\t0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "column_names = small_train_dataset.column_names\n",
        "print(column_names)\n",
        "\n",
        "features = small_train_dataset.features\n",
        "print(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBIEk5Ey49ji",
        "outputId": "27841154-8c2d-4778-e4c1-4915ff6223db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'ner_tags']\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_column_name = \"tokens\"\n",
        "label_column_name = \"ner_tags\""
      ],
      "metadata": {
        "id": "MKTNyGWl5cJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If the labels are of type ClassLabel, they are already integers and we have the map stored somewhere.\n",
        "\n",
        "label_list = features[label_column_name].feature.names\n",
        "\n",
        "label_to_id = {label_list[i]: features[label_column_name].feature.str2int( label_list[i] ) for i in range(len(label_list))}\n",
        "\n",
        "print(label_to_id)\n",
        "\n",
        "num_labels = len(label_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbAEqyhM5eo0",
        "outputId": "d7e7a000-f178-4dc4-da42-fe46cd7e15bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the next cell if you want to use a GPU. Make sure that the Colab runtime is set accordingly\n",
        "\n",
        "model=model.to(\"cuda\")"
      ],
      "metadata": {
        "id": "PN6-zrMq5ga-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk0VjAhh5n1l",
        "outputId": "bedf7bba-9bc8-4b46-9bd3-58a074f56885"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all texts and align the labels with them.\n",
        "padding = \"max_length\"\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(\n",
        "        examples[text_column_name],\n",
        "        padding=padding,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "        # We use this argument because the texts in our dataset are lists of words (with a label for each word).\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[label_column_name]):\n",
        "        # print('=====')\n",
        "        # print('{} {}'.format(i,label)) #ak\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
        "            # ignored in the loss function.\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            # We set the label for the first token of each word.\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
        "            # the label_all_tokens flag.\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "itvMJcvJ6B3D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = small_train_dataset\n",
        "train_dataset = train_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=4,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "gKaeyL8b5x8L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = raw_datasets[\"validation\"]\n",
        "eval_dataset = eval_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=4,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on Validation dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "Jb0LU10t6EYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "FYytUt6U6GVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics\n",
        "metric = load_metric(\"seqeval\")\n",
        "\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    # Remove ignored index (special tokens)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    # Unpack nested dictionaries\n",
        "    final_results = {}\n",
        "    for key, value in results.items():\n",
        "        if isinstance(value, dict):\n",
        "            for n, v in value.items():\n",
        "                final_results[f\"{key}_{n}\"] = v\n",
        "        else:\n",
        "            final_results[key] = value\n",
        "    return final_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtxyE9sn6Ip6",
        "outputId": "9bb43842-38de-40fd-c7c2-26608551c612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-435f98c90f62>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"seqeval\")\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:756: FutureWarning: The repository for seqeval contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/seqeval/seqeval.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "45jkKd3w6KW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize our Trainer\n",
        "# early_stopping_callback = EarlyStoppingCallback(early_stopping_patience=2)\n",
        "# args.metric_for_best_model = \"f1\"\n",
        "# args.load_best_model_at_end = True\n",
        "# args.evaluation_strategy = IntervalStrategy.STEPS\n",
        "# args.eval_steps = args.save_steps\n",
        "# args.greater_is_better = True\n",
        "# Define training arguments\n",
        "num_epochs=3\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=num_epochs,  # Set the number of epochs\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps=100,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10,\n",
        "    disable_tqdm=False,\n",
        "    load_best_model_at_end=True,  # Set load_best_model_at_end to True\n",
        "    learning_rate=0.0001,  # Set the learning rate here\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    data_collator=data_collator,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zez0qe956MLk",
        "outputId": "c1b99d2d-a20f-42ee-c477-59baa987e2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYKPtfZW6Ovj",
        "outputId": "1c085598-7d9e-4bd3-d859-365e9a63c253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "dispatch_batches=None,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_steps=100,\n",
              "evaluation_strategy=steps,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=False,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=False,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=0.0001,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=True,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./logs,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=10,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=linear,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=loss,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=adamw_torch,\n",
              "optim_args=None,\n",
              "output_dir=./results,\n",
              "overwrite_output_dir=False,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=16,\n",
              "per_device_train_batch_size=16,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard'],\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./results,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=500,\n",
              "save_strategy=steps,\n",
              "save_total_limit=2,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "split_batches=None,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_cpu=False,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.0,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "D06wfG6k8qoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()\n",
        "metrics = train_result.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "95TT0qSp6QnB",
        "outputId": "7fa80a29-55a7-4ad7-c5cb-439a600c5b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/3750 15:50 < 23:47, 1.58 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Loc Precision</th>\n",
              "      <th>Loc Recall</th>\n",
              "      <th>Loc F1</th>\n",
              "      <th>Loc Number</th>\n",
              "      <th>Org Precision</th>\n",
              "      <th>Org Recall</th>\n",
              "      <th>Org F1</th>\n",
              "      <th>Org Number</th>\n",
              "      <th>Per Precision</th>\n",
              "      <th>Per Recall</th>\n",
              "      <th>Per F1</th>\n",
              "      <th>Per Number</th>\n",
              "      <th>Overall Precision</th>\n",
              "      <th>Overall Recall</th>\n",
              "      <th>Overall F1</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.177500</td>\n",
              "      <td>0.293546</td>\n",
              "      <td>0.744015</td>\n",
              "      <td>0.773946</td>\n",
              "      <td>0.758685</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.636767</td>\n",
              "      <td>0.691418</td>\n",
              "      <td>0.662968</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.753128</td>\n",
              "      <td>0.780938</td>\n",
              "      <td>0.766781</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.720280</td>\n",
              "      <td>0.756426</td>\n",
              "      <td>0.737910</td>\n",
              "      <td>0.916994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.213200</td>\n",
              "      <td>0.283611</td>\n",
              "      <td>0.791841</td>\n",
              "      <td>0.725096</td>\n",
              "      <td>0.757000</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.631068</td>\n",
              "      <td>0.689489</td>\n",
              "      <td>0.658986</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.767595</td>\n",
              "      <td>0.756487</td>\n",
              "      <td>0.762001</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.735236</td>\n",
              "      <td>0.731457</td>\n",
              "      <td>0.733342</td>\n",
              "      <td>0.916093</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.164300</td>\n",
              "      <td>0.300783</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>0.755747</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.651643</td>\n",
              "      <td>0.669238</td>\n",
              "      <td>0.660324</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.728782</td>\n",
              "      <td>0.788423</td>\n",
              "      <td>0.757430</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.716156</td>\n",
              "      <td>0.749816</td>\n",
              "      <td>0.732600</td>\n",
              "      <td>0.917391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.169000</td>\n",
              "      <td>0.280933</td>\n",
              "      <td>0.729401</td>\n",
              "      <td>0.746169</td>\n",
              "      <td>0.737689</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.586460</td>\n",
              "      <td>0.693346</td>\n",
              "      <td>0.635440</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.765734</td>\n",
              "      <td>0.764970</td>\n",
              "      <td>0.765352</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.705540</td>\n",
              "      <td>0.741983</td>\n",
              "      <td>0.723303</td>\n",
              "      <td>0.915697</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.252700</td>\n",
              "      <td>0.292777</td>\n",
              "      <td>0.691189</td>\n",
              "      <td>0.773946</td>\n",
              "      <td>0.730230</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.692938</td>\n",
              "      <td>0.652845</td>\n",
              "      <td>0.672294</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.756505</td>\n",
              "      <td>0.768962</td>\n",
              "      <td>0.762683</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.723404</td>\n",
              "      <td>0.740759</td>\n",
              "      <td>0.731979</td>\n",
              "      <td>0.915552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.333000</td>\n",
              "      <td>0.256301</td>\n",
              "      <td>0.735401</td>\n",
              "      <td>0.772031</td>\n",
              "      <td>0.753271</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.688325</td>\n",
              "      <td>0.653809</td>\n",
              "      <td>0.670623</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.741981</td>\n",
              "      <td>0.784930</td>\n",
              "      <td>0.762852</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.727684</td>\n",
              "      <td>0.748348</td>\n",
              "      <td>0.737871</td>\n",
              "      <td>0.918219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.262400</td>\n",
              "      <td>0.261924</td>\n",
              "      <td>0.746896</td>\n",
              "      <td>0.749042</td>\n",
              "      <td>0.747967</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.640294</td>\n",
              "      <td>0.671167</td>\n",
              "      <td>0.655367</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.770367</td>\n",
              "      <td>0.754990</td>\n",
              "      <td>0.762601</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.729868</td>\n",
              "      <td>0.732191</td>\n",
              "      <td>0.731028</td>\n",
              "      <td>0.916814</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.166500</td>\n",
              "      <td>0.271189</td>\n",
              "      <td>0.742723</td>\n",
              "      <td>0.757663</td>\n",
              "      <td>0.750119</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.673611</td>\n",
              "      <td>0.654773</td>\n",
              "      <td>0.664059</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.756895</td>\n",
              "      <td>0.739521</td>\n",
              "      <td>0.748107</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.732324</td>\n",
              "      <td>0.722644</td>\n",
              "      <td>0.727452</td>\n",
              "      <td>0.916309</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.295800</td>\n",
              "      <td>0.256300</td>\n",
              "      <td>0.745024</td>\n",
              "      <td>0.752874</td>\n",
              "      <td>0.748928</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.686408</td>\n",
              "      <td>0.681774</td>\n",
              "      <td>0.684083</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.739456</td>\n",
              "      <td>0.787425</td>\n",
              "      <td>0.762687</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.727898</td>\n",
              "      <td>0.751775</td>\n",
              "      <td>0.739644</td>\n",
              "      <td>0.919193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.291300</td>\n",
              "      <td>0.258744</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>0.717433</td>\n",
              "      <td>0.745274</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.724138</td>\n",
              "      <td>0.627772</td>\n",
              "      <td>0.672521</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.755898</td>\n",
              "      <td>0.783433</td>\n",
              "      <td>0.769419</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.753425</td>\n",
              "      <td>0.727050</td>\n",
              "      <td>0.740002</td>\n",
              "      <td>0.918616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.268100</td>\n",
              "      <td>0.247871</td>\n",
              "      <td>0.731115</td>\n",
              "      <td>0.778736</td>\n",
              "      <td>0.754174</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.653631</td>\n",
              "      <td>0.676953</td>\n",
              "      <td>0.665088</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.745014</td>\n",
              "      <td>0.782934</td>\n",
              "      <td>0.763504</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.718546</td>\n",
              "      <td>0.754957</td>\n",
              "      <td>0.736302</td>\n",
              "      <td>0.918075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.237300</td>\n",
              "      <td>0.255267</td>\n",
              "      <td>0.754402</td>\n",
              "      <td>0.779693</td>\n",
              "      <td>0.766839</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.662628</td>\n",
              "      <td>0.685632</td>\n",
              "      <td>0.673934</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.730751</td>\n",
              "      <td>0.790918</td>\n",
              "      <td>0.759645</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.719741</td>\n",
              "      <td>0.761322</td>\n",
              "      <td>0.739948</td>\n",
              "      <td>0.917715</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.273091</td>\n",
              "      <td>0.748837</td>\n",
              "      <td>0.771073</td>\n",
              "      <td>0.759792</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.667308</td>\n",
              "      <td>0.669238</td>\n",
              "      <td>0.668272</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.757122</td>\n",
              "      <td>0.782435</td>\n",
              "      <td>0.769571</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.732680</td>\n",
              "      <td>0.750796</td>\n",
              "      <td>0.741627</td>\n",
              "      <td>0.917174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.213000</td>\n",
              "      <td>0.272804</td>\n",
              "      <td>0.732636</td>\n",
              "      <td>0.737548</td>\n",
              "      <td>0.735084</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.628947</td>\n",
              "      <td>0.691418</td>\n",
              "      <td>0.658705</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.742481</td>\n",
              "      <td>0.788423</td>\n",
              "      <td>0.764763</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.710118</td>\n",
              "      <td>0.750796</td>\n",
              "      <td>0.729891</td>\n",
              "      <td>0.915877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.179900</td>\n",
              "      <td>0.272238</td>\n",
              "      <td>0.712785</td>\n",
              "      <td>0.779693</td>\n",
              "      <td>0.744739</td>\n",
              "      <td>1044</td>\n",
              "      <td>0.625967</td>\n",
              "      <td>0.702025</td>\n",
              "      <td>0.661818</td>\n",
              "      <td>1037</td>\n",
              "      <td>0.742518</td>\n",
              "      <td>0.779940</td>\n",
              "      <td>0.760769</td>\n",
              "      <td>2004</td>\n",
              "      <td>0.704082</td>\n",
              "      <td>0.760098</td>\n",
              "      <td>0.731018</td>\n",
              "      <td>0.916850</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='391' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 02:34]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Checkpoint destination directory ./results/checkpoint-500 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "metrics = trainer.evaluate()\n",
        "\n",
        "trainer.log_metrics(\"eval\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "eVoFup_w6UPa",
        "outputId": "578d8613-5d59-4e06-ca29-5122e164f6ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='169' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 00:22]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** eval metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.7453\n",
            "  eval_LOC_number         =       1044\n",
            "  eval_LOC_precision      =     0.7754\n",
            "  eval_LOC_recall         =     0.7174\n",
            "  eval_ORG_f1             =     0.6725\n",
            "  eval_ORG_number         =       1037\n",
            "  eval_ORG_precision      =     0.7241\n",
            "  eval_ORG_recall         =     0.6278\n",
            "  eval_PER_f1             =     0.7694\n",
            "  eval_PER_number         =       2004\n",
            "  eval_PER_precision      =     0.7559\n",
            "  eval_PER_recall         =     0.7834\n",
            "  eval_loss               =     0.2587\n",
            "  eval_overall_accuracy   =     0.9186\n",
            "  eval_overall_f1         =       0.74\n",
            "  eval_overall_precision  =     0.7534\n",
            "  eval_overall_recall     =     0.7271\n",
            "  eval_runtime            = 0:00:23.97\n",
            "  eval_samples_per_second =    112.628\n",
            "  eval_steps_per_second   =       7.05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = raw_datasets['test']\n",
        "test_dataset = test_dataset.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "id": "9dE89YyS6Upl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test_dataset)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "D9hNX80H-r7J",
        "outputId": "3343e166-c1ba-4790-806c-e22161a0bb51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='222' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 00:31]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.7886\n",
            "  eval_LOC_number         =        483\n",
            "  eval_LOC_precision      =     0.8372\n",
            "  eval_LOC_recall         =     0.7453\n",
            "  eval_ORG_f1             =      0.668\n",
            "  eval_ORG_number         =        263\n",
            "  eval_ORG_precision      =        0.7\n",
            "  eval_ORG_recall         =     0.6388\n",
            "  eval_PER_f1             =     0.8297\n",
            "  eval_PER_number         =        609\n",
            "  eval_PER_precision      =     0.8438\n",
            "  eval_PER_recall         =     0.8161\n",
            "  eval_loss               =      0.205\n",
            "  eval_overall_accuracy   =     0.9364\n",
            "  eval_overall_f1         =     0.7842\n",
            "  eval_overall_precision  =     0.8141\n",
            "  eval_overall_recall     =     0.7565\n",
            "  eval_runtime            = 0:00:07.50\n",
            "  eval_samples_per_second =    112.915\n",
            "  eval_steps_per_second   =      7.066\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset, Features, ClassLabel, Value, Sequence\n",
        "\n",
        "# Assuming your data is structured like this:\n",
        "data = [\n",
        "{   \"tokens\": [     \"అయితే\",     \"ఈ\",     \"సారి\",     \"అనూహ్యంగా\",     \"కోటి\",     \"యాభై\",     \"లక్షల\",     \"పలకడంతో\",     \"ఆ\",     \"డబ్బును\",     \"ఏం\",     \"చేయాలో\",     \"ఇంకా\",     \"నిర్ణయించుకోలేదని\",     \"గోయట్\",     \"చెప్పుకొచ్చాడు\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "{   \"tokens\": [     \"ప్రజల\",     \"మనోభావాలు,\",     \"ఎమోషన్స్\",     \"కి\",     \"అంతగా\",     \"ప్రాముఖ్యత\",     \"ఇవ్వకుండా\",     \"తానుఅనుకున్న\",     \"పనులు\",     \"చక్కబెట్టేవారు\",   \" .\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",  \"O\"   ] },\n",
        "{   \"tokens\": [     \"అప్పుడు,\",     \"మీరు\",     \"చివరకు\",     \"చూస్తున్న\",     \"పెరుగుదల\",     \"అలవాటు\",     \"రకం\",     \"ప్రోత్సహించడానికి\",     \"న్యాయమైన\",     \"కట్స్\",     \"తయారు\",  \".\"  ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\", \"O\"   ] },\n",
        "{   \"tokens\": [ \"ఎన్నికల\", \"ప్రకటన\", \"వెలువడినది\", \"లగాయతు\", \"సీట్ల\", \"పంపకం\", \"కోసం\", \"కొట్టుకోవడమే\", \"మహాకూటమికి\", \"సరిపోతున్నది\", \"ప్రతిరోజూ\", \"ఉదయం\", \"ఇంట్లో\", \"టిఫిన్\", \"చెయ్యడం\", \"గోల్కొండ\", \"రిసారట్స్కు\", \"వెళ్లి\", \"పిచ్చాపాటీ\", \"మాట్లాడుకుని\", \"భోజనం\", \"చెయ్యడం\", \"ఇంటికి\", \"వెళ్లడం\", \"మరునాడు\", \"మళ్ళీ\", \"అదే\", \"తంతు\", \"కాంగ్రెస్\", \"పార్టీకి\", \"కార్యకర్తలు\", \"తక్కువ\", \"నాయకులు\", \"ఎక్కువ\", \"సర్పంచ్\", \"గా\", \"కూడా\", \"చేయనివాడు\", \"ముఖ్యమంత్రి\", \"కావాలనుకుంటారు\", \"ఆ\", \"పార్టీలో\", \"అందుకే\", \"ఎప్పుడు\", \"ఎన్నికలు\", \"వచ్చినా\", \"కాంగ్రెస్\", \"పార్టీలో\", \"అంతర్గత\", \"యుద్ధం\", \"మొదలవుతుంది\", \"వారికి\", \"వారే\", \"వెన్నుపోట్లు\", \"పొడుచుకుంటారు\", \"తమకు\", \"ముప్ఫయి\", \"సీట్లు\", \"కావాలని\", \"టీజేఎస్\", \"తమకు\", \"నలభై\", \"కావాలని\", \"తెలుగుదేశం\", \"కాంగ్రెస్\", \"పార్టీకి\", \"హెచ్చరికలు\", \"జారీ\", \"చేస్తున్నాయి\", \"లేకపోతె\", \"తమ\", \"దారి\", \"తాము\", \"చూసుకుంటామని\", \"బెదిరింపులకు\", \"దిగుతున్నాయి\", \"ఆ\", \"రెండు\", \"పార్టీలకే\", \"అరవై\", \"డ్బ్బై\", \"స్థానాలు\", \"ఇచ్చి\", \"ఇక\", \"కాంగ్రెస్\", \"పోటీ\", \"చేసేది\", \"ఎన్ని\", \"స్థానాలలో\", \"నవ్వు\", \"రావడం\", \"లేదూ\", \"ఎన్నికలు\", \"అయ్యేంతవరకూ\", \"పరస్పరం\", \"కలహించుకోవడంలోనే\", \"కాలక్షేపం\", \"మహాకూటమి\", \"ఎన్నికల్లో\", \"పోటీ\", \"చేసి\", \"విజయం\", \"సాధించడం\", \"అయ్యేపనేనా\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"I-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"B-ORG\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"మెగా\", \"పవర్\", \"స్టార్\", \"రామ్\", \"చరణ్\", \",\", \"ఊరమాస్\", \"డైరెక్టర్\", \"బోయపాటి\", \"శ్రీను\", \"కాంబినేషన్‌లో\", \",\", \"ఫ్యామిలీ\", \",\", \"లవ్\", \"అండ్\", \"యాక్షన్\", \"ఎంటర్‌టైనర్‌గా\", \"రూపొందిన\", \"వినయ\", \"విధేయ\", \"రామ్\", \",\", \"జనవరి\", \"11న\", \"వరల్డ్\", \"వైడ్\", \"గ్రాండ్\", \"రిలీజ్‌కి\", \"రెఢీ\", \"అయిపోయింది\", \".\", \"డి.వి.వి.\", \"దానయ్య\", \"నిర్మించగా\", \",\", \"కైరా\", \"అద్వాణీ\", \"హీరోయిన్‌గా\", \"నటించింది\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"అది,\", \"పొందుటకు\", \",\",  \"మేము\", \"ప్రధాన\", \"ద్వారం\", \"నుండి\", \"కుడి\", \"చెయ్యి\", \"మరియు\", \"నిరంతరం\", \"పెరుగుతుంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "  { \"tokens\": [ \"లోతైన\", \"సమావేశంలో\", \",\", \"సారాంశం\", \"మానవ\", \"శరీరంలో\", \"నుండి\", \"వేరు\", \",\", \"అస్తిత్వ\", \"మరణం\", \"అని\", \"పిలువబడుతుంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"చాటుసాహిత్యంలో\", \"తరచూ\", \"కనిపించే\", \"లక్షణం\", \"–\", \"పద్యాల\", \"గురించీ\", \",\", \"కవుల\", \"గురించీ\", \"జనవ్యవహారంలో\", \"వ్యాప్తమైయ్యే\", \"కథలు\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\",  \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"బ్రేకింగ్\", \":\", \"మళ్ళీ\", \"వైసీపీలోకి\", \"ఎంట్రీ\", \"ఇస్తున్న\", \"కీలక\", \"నేత\", \"..\", \"షాక్‌లో\", \"టీడీపీ\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\"] },\n",
        " { \"tokens\": [ \"ప్రామాణిక\", \"బ్యాంకు\", \"రుణ\", \"జారీ\", \"కాకుండా\", \",\", \"క్రెడిట్\", \"యొక్క\", \"లైన్\", \"ఆర్థిక\", \"సంస్థల\", \"రుణగ్రహీతలు\", \"మరింత\", \"ఆకర్షణీయంగా\", \",\", \"అలాగే\", \"ఉంది\", \".\" ], \"ner_tags\": [ \"O\", \"B-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"I-ORG\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"వారి\", \"ప్రకాశవంతమైన\", \"నక్షత్రాలు\", \"సిరియస్\", \"మరియు\", \"Procyon\", \"ఏ\", \"ఇతర\", \"తో\", \"తికమక\", \"కష్టం\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"పీటర్స్బర్గ్\", \"పతనం\", \"తరువాత\", \"లీ\", \"యొక్క\", \"వెనుకవైపు\", \"ఉన్న\", \"సైనికదళాన్ని\", \"కొనసాగించడంతో\", \",\",  \"రైట్\", \"మరియు\", \"VI\", \"కార్ప్స్\", \"మళ్లీ\", \"షెరిడాన్\", \"దిశగా\", \"వచ్చారు\", \".\" ], \"ner_tags\": [ \"B-PER\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"B-PER\",  \"O\", \"B-LOC\", \"O\", \"O\", \"O\" ] },\n",
        " { \"tokens\": [ \"దానిపై\", \"హైడ్\", \"ప్రదర్శన\", \"లక్షణాలు\", \"ఒక\", \"ప్రాథమిక\", \"వివరణ\", \"తో\", \"ప్రారంభం\", \"కావాలి\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        "{ \"tokens\": [ \"మోరెనా\", \"జిల్లా\", \"జౌరా\", \"ప్రాంతంలో\", \"జరిగిన\", \"ఒక\", \"ఎన్నికల\", \"సభలో\", \"రాహుల్\", \"మాట్లాడుతూ\", \"ఎంజే\", \"అక్బర్‌పై\", \"పలువురు\", \"మహిళా\", \"జర్నలిస్టులు\", \"చేసిన\", \"లైంగిక\", \"దాడి\", \"ఆరోపణలను\", \"దృష్టిలో\", \"పెట్టుకొని\", \"మోదీ\", \"ప్రభుత్వాన్ని\", \"నిలదీశారు\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-LOC\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\" ] },\n",
        "\n",
        " #  { \"tokems\": [ \"కాన్స్టాంటినోపుల్లో\", \"బోహెంండ్\", \"ముఖ్యంగా\", \"స్వాగతం\", \"లేదు\", \"ఎందుకంటే\", \"అతని\", \"తండ్రి\", \",\", \"రాబర్ట్\", \"గైకార్డ్\", \",\", \"బైజాంటైన్\", \"సామ్రాజ్యాన్ని\", \"ఆక్రమించి\", \",\", \"డియర్హచ్యూమ్\", \"మరియు\", \"కోర్ఫు\", \"నగరాలను\", \"స్వాధీనం\", \"చేసుకున్నాడు\", \".\" ], \"ner_tags\": [ 6, 1, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 6, 0, 0, 0, 6, 0, 6, 0, 0, 0, 0 ] },\n",
        " #   { \"tokems\": [ \"శిఖరం\", \"(\", \"ఉత్తమ\", \"సమయం\", \"-\", \"సాయంత్రం\", \"ముఖ్యంగా\", \"“\", \"వర్షం\", \"కింద\", \"“\", \")\", \"యొక్క\", \"వేడి\", \"మానుకోండి\", \";\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #  { \"tokems\": [ \"ఏదైనా\", \"ఒక\", \"నీటి\", \"పారుదల\", \"ప్రాజెక్టుకు\", \"జాతీయ\", \"హోదాను\", \"ఇవ్వాలని\", \"కోరే\", \"అవకాశం\", \"ఉంది\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " #{ \"tokems\": [ \"ప్రైవేట్స్‌\", \"పోల్స్‌ను\", \"బట్టి\", \"చూస్తే\", \"వితిక\", \"పరిస్థితి\", \"మాత్రం\", \"దారుణంగా\", \"ఉన్నట్లు\", \"తెలుస్తోంది\", \".\" ], \"ner_tags\": [ 0,0,0,0,0,0,0,0,0,0,0 ] },\n",
        " # { \"tokems\": [ \"బంగ్లా\", \"ఓపెనర్\", \"షాద్‌మన్‌\", \"ఇస్లామ్‌.\", \"(\", \"29\", \")\", \"ఫర్వాలేదనిపించగా\", \"...\", \"మరో\", \"ఓపెనర్\", \"ఇమ్రుల్‌\", \"(\", \"4\", \")\", \"నిరాశపరిచాడు\", \".\" ], \"ner_tags\": [ \"B-LOC\", \"O\", \"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-PER\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # { \"tokems\": [ \"అయితే\", \"వాటికి\", \"హైనెక్‌\", \"బ్లవుజులు\", \",\", \"కాలర్స్‌\", \",\", \"ఫుల్‌స్లీవ్స్‌\", \",\", \"క్లోజ్డ్‌\", \",\", \"బోట్‌\", \",\", \"బ్యాక్‌హైనెక్\", \"‌,\", \"ఫ్రంట్‌\", \"రౌండ్‌నెక్‌\", \"బ్లవుజ్‌లు\", \"బాగుంటాయి\", \".\" ], \"ner_tags\": [ \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\", \"O\" ] },\n",
        " # {    \"tokems\": [     \"4\",     \")\",     \"పైన\",     \"చెప్పిన\",     \"వి\",     \"అనగా\",     \"కలిపి\",     \"పెట్టుకున్న\",     \"రవ్వ\",     \",\",     \"ఉడికించిన\",     \"ఆలూ\",     \",\",     \"కట్\",     \"చెసి\",     \"పెట్టకున్నవి\",     \"అన్ని\",     \"ఇంకా\",     \"జిలకర్ర\",     \",\",     \"ఉప్పు\",     \"రుచి\",     \"కి\",     \"సరిపడ\",     \".\",     \"వెసి\",     \"ముద్ద\",     \"లా\",     \"కలుపుకోవాలీ\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] },\n",
        " #{   \"tokems\": [     \"సినిమాలో\",     \"కంటెంట్\",     \"అంతంతమాత్రమే\",     \"అయినప్పటికీ\",     \"..\",     \"ఈ\",     \"మాత్రం\",     \"వసూళ్లు\",     \"వచ్చాయంటే\",     \"అది\",     \"ఎన్టీఆర్\",     \"పెర్ఫామెన్స్‌\",     \"వల్లే\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"B-PER\",     \"O\",     \"O\"   ] },\n",
        "  #{   \"tokems\": [     \"‘\",     \"స్టార్స్\",     \"‌’\",     \"(\",     \"స్కీమ్‌\",     \"ఫర్‌\",     \"ట్రాన్స్‌ఫర్మేషన్‌\",     \"అండ్‌\",     \"అడ్వాన్స్‌డ్‌\",     \"రీసెర్చ్‌\",     \"ఇన్‌\",     \"బేసిక్‌\",     \"సైన్సెస్\",     \")\",     \",\",     \"ఐఐఎస్‌సీ\",     \"బెంగళూరు\",     \"ద్వారా\",     \"అధ్యయన\",     \"కార్యక్రమాలను\",     \"మంజూరు\",     \"చేస్తున్నారు\",     \".\"   ],   \"ner_tags\": [     \"O\",     \"O\",     \"O\",     \"O\",     \"B-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"I-ORG\",     \"O\",     \"O\",     \"B-ORG\",     \"B-LOC\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\",     \"O\"   ] }\n",
        "    # More records...\n",
        "]\n",
        "\n",
        "# Transform your list of dictionaries into the expected format\n",
        "transformed_data = {\n",
        "    \"tokens\": [item[\"tokens\"] for item in data],\n",
        "    \"ner_tags\": [item[\"ner_tags\"] for item in data],\n",
        "}\n",
        "\n",
        "# Define the features of your dataset, aligning with your manual data structure\n",
        "features = Features({\n",
        "    'tokens': Sequence(feature=Value(dtype='string')),\n",
        "    'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']))\n",
        "})\n",
        "\n",
        "# Create a Dataset object from your transformed data\n",
        "question1_data = Dataset.from_dict(transformed_data, features=features)\n",
        "\n",
        "# Now you can access column_names and features just like your training dataset\n",
        "column_names = question1_data.column_names\n",
        "print(column_names)\n",
        "\n",
        "dataset_features = question1_data.features\n",
        "print(dataset_features)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0k09Md1_nJ6",
        "outputId": "f1ee906e-7621-492c-d503-764adecba996"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tokens', 'ner_tags']\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = question1_data\n",
        "test = test.map(\n",
        "    tokenize_and_align_labels,\n",
        "    batched=True,\n",
        "    num_proc=6,\n",
        "    load_from_cache_file=True,\n",
        "    desc=\"Running tokenizer on train dataset\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2232ff5a7d274706a74bbaf1b6bdbadc",
            "c4a35520eb1d4550808d1c20930d4e1b",
            "fe67a50711d449ff91362506fffd27f1",
            "c19bf97e8999485b9074115e122b28ed",
            "b2dfa01082744d19b72dc9d035755211",
            "652736cc03454854ad10c47657edbf1f",
            "eeafacca2a144d20864d36ddb20a0913",
            "4051e27c50544d6bb6b2416518aa5ac6",
            "87b84eb3406545b3a96b0835cc2800f3",
            "c118ba6bc38b45a3858d28a2eb20a515",
            "2e44032a27d144acb3bf98b5255b4d81"
          ]
        },
        "id": "O5R_Od5_DtZD",
        "outputId": "07c62e9d-45ae-47ad-97e9-40060034e32d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Running tokenizer on train dataset (num_proc=6):   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2232ff5a7d274706a74bbaf1b6bdbadc"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate on the test dataset\n",
        "metrics = trainer.evaluate(test)\n",
        "\n",
        "trainer.log_metrics(\"test\", metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "9LDReNDsDwMc",
        "outputId": "7560117a-7c6a-4ec1-e719-3636bd224606"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='223' max='169' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [169/169 07:38]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "***** test metrics *****\n",
            "  epoch                   =        1.2\n",
            "  eval_LOC_f1             =     0.3333\n",
            "  eval_LOC_number         =          5\n",
            "  eval_LOC_precision      =        1.0\n",
            "  eval_LOC_recall         =        0.2\n",
            "  eval_ORG_f1             =     0.4706\n",
            "  eval_ORG_number         =         11\n",
            "  eval_ORG_precision      =     0.6667\n",
            "  eval_ORG_recall         =     0.3636\n",
            "  eval_PER_f1             =     0.5385\n",
            "  eval_PER_number         =         14\n",
            "  eval_PER_precision      =     0.5833\n",
            "  eval_PER_recall         =        0.5\n",
            "  eval_loss               =      0.335\n",
            "  eval_overall_accuracy   =     0.9034\n",
            "  eval_overall_f1         =     0.4898\n",
            "  eval_overall_precision  =     0.6316\n",
            "  eval_overall_recall     =        0.4\n",
            "  eval_runtime            = 0:00:00.16\n",
            "  eval_samples_per_second =     83.646\n",
            "  eval_steps_per_second   =      5.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAa_9Z26FMA9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}